#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäº InsightFace çš„äººè„¸åŒ¹é…å™¨ - ä½¿ç”¨ç›¸ä¼¼åº¦åŒ¹é…æ‰¾åˆ°æœ€åƒçš„äºº
ä¸“é—¨ä¸ºäººè„¸è¯†åˆ«ä¼˜åŒ–ï¼Œæ¯” CLIP æ›´å‡†ç¡®
"""

from __future__ import annotations

import os
import glob
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import cv2


import numpy as np

try:
    import insightface
    from insightface.app import FaceAnalysis
    INSIGHTFACE_AVAILABLE = True
except ImportError:
    INSIGHTFACE_AVAILABLE = False
    print("âš ï¸  insightface åº“æœªå®‰è£…ï¼ŒInsightFaceäººè„¸åŒ¹é…åŠŸèƒ½ä¸å¯ç”¨")
    print("   å®‰è£…å‘½ä»¤: pip install insightface onnxruntime-gpu")

# æ£€æµ‹ GPU æ˜¯å¦å¯ç”¨
def _check_gpu_available():
    """æ£€æŸ¥ ONNX Runtime GPU æ˜¯å¦å¯ç”¨"""
    try:
        import onnxruntime as ort
        providers = ort.get_available_providers()
        if 'CUDAExecutionProvider' in providers:
            return True
        return False
    except Exception:
        return False

GPU_AVAILABLE = _check_gpu_available()


@dataclass
class MatchResult:
    """åŒ¹é…ç»“æœ"""
    name: str                    # åŒ¹é…çš„äººå
    similarity: float            # ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
    all_similarities: Optional[Dict[str, float]] = None  # æ‰€æœ‰äººçš„ç›¸ä¼¼åº¦


class InsightFaceMatcher:
    """
    åŸºäº InsightFace çš„äººè„¸åŒ¹é…å™¨
    
    ä½¿ç”¨æ–¹å¼:
        1. åˆå§‹åŒ–æ—¶åŠ è½½ç…§ç‰‡åº“: matcher = InsightFaceMatcher(photo_folder="photos/")
        2. æˆ–æ‰‹åŠ¨åŠ è½½: matcher.load_photo_database("photos/")
        3. åŒ¹é…äººè„¸: result = matcher.match(face_image)
    """

    def __init__(
        self,
        photo_folder: Optional[str] = None,
        threshold: float = 0.2,
        model_name: str = "buffalo_l",
        ctx_id: int = 0,
        use_gpu: bool = True,
    ):
        """
        åˆå§‹åŒ– InsightFace äººè„¸åŒ¹é…å™¨ (GPU åŠ é€Ÿç‰ˆæœ¬)
        
        Args:
            photo_folder: äººè„¸ç…§ç‰‡åº“æ–‡ä»¶å¤¹è·¯å¾„
                - æ–¹å¼1: æ–‡ä»¶å¤¹ä¸‹ç›´æ¥æ”¾å›¾ç‰‡ï¼Œæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºäººå
                - æ–¹å¼2: æ–‡ä»¶å¤¹ä¸‹æœ‰å­æ–‡ä»¶å¤¹ï¼Œå­æ–‡ä»¶å¤¹åä½œä¸ºäººåï¼Œé‡Œé¢æ”¾è¯¥äººçš„å¤šå¼ ç…§ç‰‡
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è¿”å›"æœªçŸ¥äººå‘˜"ï¼ˆé»˜è®¤0.2ï¼ŒèŒƒå›´0-1ï¼‰
            model_name: InsightFace æ¨¡å‹åç§° (buffalo_l, buffalo_s, buffalo_sc)
            ctx_id: GPU ID (0, 1, 2...)ï¼Œ-1 è¡¨ç¤º CPU
            use_gpu: æ˜¯å¦ä½¿ç”¨ GPU åŠ é€Ÿï¼ˆé»˜è®¤ Trueï¼‰
        """
        if not INSIGHTFACE_AVAILABLE:
            raise RuntimeError("insightface åº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨ InsightFace äººè„¸åŒ¹é…")
        
        self.threshold = 0
        self.model_name = model_name
        
        # ç¡®å®šä½¿ç”¨ GPU è¿˜æ˜¯ CPU
        if use_gpu and GPU_AVAILABLE:
            self.ctx_id = ctx_id if ctx_id >= 0 else 0
            providers = [
                ('CUDAExecutionProvider', {
                    'device_id': self.ctx_id,
                    'arena_extend_strategy': 'kNextPowerOfTwo',
                    'gpu_mem_limit': 4 * 1024 * 1024 * 1024,  # 4GB æ˜¾å­˜é™åˆ¶
                    'cudnn_conv_algo_search': 'EXHAUSTIVE',
                }),
                'CPUExecutionProvider'
            ]
            device_str = f"ğŸš€ GPU {self.ctx_id}"
        else:
            self.ctx_id = -1
            providers = ['CPUExecutionProvider']
            device_str = "ğŸ’» CPU"
            if use_gpu and not GPU_AVAILABLE:
                print("âš ï¸  GPU ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU æ¨¡å¼")
                print("   å®‰è£… GPU æ”¯æŒ: pip install onnxruntime-gpu")
        
        # åˆå§‹åŒ–äººè„¸åˆ†æå™¨
        print(f"ğŸ”„ åŠ è½½ InsightFace æ¨¡å‹: {model_name} (è®¾å¤‡: {device_str})")
        self.app = FaceAnalysis(
            name=model_name,
            providers=providers
        )
        self.app.prepare(ctx_id=self.ctx_id, det_size=(640, 640))
        print(f"âœ… InsightFace æ¨¡å‹åŠ è½½å®Œæˆ ({device_str})")

        # äººè„¸ç‰¹å¾æ•°æ®åº“: {äººå: ç‰¹å¾å‘é‡}
        self.face_database: Dict[str, np.ndarray] = {}
        # æ¯ä¸ªäººçš„æ‰€æœ‰ç‰¹å¾ï¼ˆç”¨äºå¤šå›¾åŒ¹é…ï¼‰
        self.face_all_embeddings: Dict[str, List[np.ndarray]] = {}
        
        # å¦‚æœæä¾›äº†ç…§ç‰‡æ–‡ä»¶å¤¹ï¼Œè‡ªåŠ¨åŠ è½½
        if photo_folder:
            self.load_photo_database(photo_folder)

    @property
    def num_people(self) -> int:
        """è¿”å›æ•°æ®åº“ä¸­çš„äººæ•°"""
        return len(self.face_database)

    def _match_single_face(self, face_crop: np.ndarray) -> MatchResult:
        """
        åŒ¹é…å•ä¸ªäººè„¸ï¼ˆå†…éƒ¨æ–¹æ³•ï¼Œç”¨äºå¤šçº¿ç¨‹ï¼‰
        
        Args:
            face_crop: è£å‰ªçš„äººè„¸å›¾åƒ (BGR)
            
        Returns:
            MatchResult: åŒ¹é…ç»“æœ
        """
        if face_crop is None or face_crop.size == 0:
            return MatchResult(name="æœªçŸ¥äººå‘˜", similarity=0.0, all_similarities=None)
        
        # æå–ç‰¹å¾
        query_emb = self._extract_embedding_from_crop(face_crop)
        
        if query_emb is None:
            return MatchResult(name="æœªçŸ¥äººå‘˜", similarity=0.0, all_similarities=None)
        
        # ä¸æ•°æ®åº“åŒ¹é…ï¼Œæ‰¾æœ€ä¼˜
        all_similarities = {}
        for name, db_emb in self.face_database.items():
            sim = self._compute_similarity(query_emb, db_emb)
            all_similarities[name] = sim
        
        best_name = max(all_similarities, key=all_similarities.get)
        best_sim = all_similarities[best_name]
        
        # ç½®ä¿¡åº¦é˜ˆå€¼åˆ¤æ–­
        if best_sim < self.threshold:
            return MatchResult(
                name="æœªçŸ¥äººå‘˜",
                similarity=best_sim,
                all_similarities=all_similarities
            )
        
        return MatchResult(
            name=best_name,
            similarity=best_sim,
            all_similarities=all_similarities
        )

    def match_all_faces_in_image(self, full_image: np.ndarray, yolo_bboxes: list, num_threads: int = 4) -> list:
        """
        æ‰¹é‡åŒ¹é…å¤šä¸ª YOLO æ£€æµ‹çš„äººè„¸ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼šä¿ç•™äººè„¸å¯¹é½ + å¿«é€ŸåŒ¹é…ï¼‰
        
        ç›´æ¥ä½¿ç”¨ YOLO çš„ bbox è£å‰ªäººè„¸ï¼Œæå–ç‰¹å¾åä¸æ•°æ®åº“åŒ¹é…
        
        Args:
            full_image: å®Œæ•´çš„ BGR å›¾åƒ
            yolo_bboxes: YOLO æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†åˆ—è¡¨ [[x1, y1, x2, y2], ...]
            num_threads: å¹¶è¡Œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤ 4ï¼‰
            
        Returns:
            list: [MatchResult, ...] ä¸ yolo_bboxes ä¸€ä¸€å¯¹åº”
        """
        from concurrent.futures import ThreadPoolExecutor
        
        if len(self.face_database) == 0:
            return [MatchResult(name="æœªçŸ¥äººå‘˜", similarity=0.0, all_similarities=None) 
                    for _ in yolo_bboxes]
        
        if len(yolo_bboxes) == 0:
            return []
        
        h, w = full_image.shape[:2]
        
        # é¢„è®¡ç®—æ•°æ®åº“ç‰¹å¾çŸ©é˜µï¼ˆåªéœ€è®¡ç®—ä¸€æ¬¡ï¼‰
        if not hasattr(self, '_db_matrix') or self._db_matrix is None:
            self._build_db_matrix()
        
        # é¢„å…ˆè£å‰ªæ‰€æœ‰äººè„¸
        face_crops = []
        valid_indices = []
        
        for idx, yolo_bbox in enumerate(yolo_bboxes):
            x1, y1, x2, y2 = yolo_bbox
            x1, y1 = max(0, int(x1)), max(0, int(y1))
            x2, y2 = min(w, int(x2)), min(h, int(y2))
            
            if x2 > x1 + 20 and y2 > y1 + 20:  # æœ€å°å°ºå¯¸æ£€æŸ¥
                face_crop = full_image[y1:y2, x1:x2].copy()
                face_crops.append(face_crop)
                valid_indices.append(idx)
        
        # åˆå§‹åŒ–ç»“æœ
        results = [MatchResult(name="æœªçŸ¥äººå‘˜", similarity=0.0, all_similarities=None) 
                   for _ in yolo_bboxes]
        
        if not face_crops:
            return results
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæå–ç‰¹å¾ï¼ˆä¿ç•™äººè„¸å¯¹é½ï¼‰
        def _extract_and_match(face_crop):
            emb = self._extract_embedding_from_crop(face_crop)
            if emb is not None:
                return self._match_embedding_fast(emb)
            return MatchResult(name="æœªçŸ¥äººå‘˜", similarity=0.0, all_similarities=None)
        
        # å¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=min(num_threads, len(face_crops))) as executor:
            match_results = list(executor.map(_extract_and_match, face_crops))
        
        # å†™å›ç»“æœ
        for idx, result in zip(valid_indices, match_results):
            results[idx] = result
        
        return results
    
    def _build_db_matrix(self):
        """æ„å»ºæ•°æ®åº“ç‰¹å¾çŸ©é˜µï¼Œç”¨äºå¿«é€Ÿæ‰¹é‡åŒ¹é…"""
        if len(self.face_database) == 0:
            self._db_matrix = None
            self._db_names = []
            return
        
        self._db_names = list(self.face_database.keys())
        embeddings = [self.face_database[name] for name in self._db_names]
        self._db_matrix = np.array(embeddings)
        # å½’ä¸€åŒ–
        norms = np.linalg.norm(self._db_matrix, axis=1, keepdims=True)
        self._db_matrix = self._db_matrix / norms
    
    def _match_embedding_fast(self, embedding: np.ndarray) -> MatchResult:
        """
        å¿«é€ŸåŒ¹é…å•ä¸ªç‰¹å¾å‘é‡ï¼ˆä½¿ç”¨é¢„è®¡ç®—çš„çŸ©é˜µï¼Œå‘é‡åŒ–è®¡ç®—ï¼‰
        """
        if self._db_matrix is None or len(self._db_names) == 0:
            return MatchResult(name="æœªçŸ¥äººå‘˜", similarity=0.0, all_similarities=None)
        
        # å½’ä¸€åŒ–æŸ¥è¯¢å‘é‡
        emb_norm = embedding / np.linalg.norm(embedding)
        
        # æ‰¹é‡è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆå‘é‡åŒ–ï¼Œæ¯”å¾ªç¯å¿«ï¼‰
        similarities = np.dot(self._db_matrix, emb_norm)
        similarities = (similarities + 1) / 2  # æ˜ å°„åˆ° 0-1
        
        best_idx = np.argmax(similarities)
        best_name = self._db_names[best_idx]
        best_sim = float(similarities[best_idx])
        
        if best_sim < self.threshold:
            return MatchResult(name="æœªçŸ¥äººå‘˜", similarity=best_sim, all_similarities=None)
        
        return MatchResult(name=best_name, similarity=best_sim, all_similarities=None)
    
    def _extract_embedding_from_crop(self, face_crop: np.ndarray) -> Optional[np.ndarray]:
        """
        ä»è£å‰ªçš„äººè„¸å›¾åƒä¸­æå–ç‰¹å¾
        
        ä¼˜å…ˆä½¿ç”¨ InsightFace è¿›è¡Œå…³é”®ç‚¹æ£€æµ‹å’Œå¯¹é½ï¼ˆç²¾åº¦é«˜ï¼‰ï¼Œ
        å¦‚æœæ£€æµ‹å¤±è´¥åˆ™å›é€€åˆ°ç›´æ¥æå–ç‰¹å¾ï¼ˆä¿è¯æœ‰è¾“å‡ºï¼‰
        
        Args:
            face_crop: è£å‰ªçš„äººè„¸å›¾åƒ (BGR)
            
        Returns:
            512ç»´ç‰¹å¾å‘é‡ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å› None
        """
        if face_crop is None or face_crop.size == 0:
            return None
        
        h, w = face_crop.shape[:2]
        
        # # æ–¹æ¡ˆ1ï¼šæ·»åŠ è¾¹è·åå†æ£€æµ‹ï¼ˆå¤„ç†äººè„¸å¤ªé è¾¹çš„æƒ…å†µï¼‰
        # # è¾¹è·å¤§å°æ ¹æ®äººè„¸å°ºå¯¸åŠ¨æ€è°ƒæ•´ï¼Œå¹¶ä½¿ç”¨è¾¹ç¼˜å¤åˆ¶å¡«å……
        pad = max(40, int(min(h, w) * 0.1))
        padded = cv2.copyMakeBorder(face_crop, pad, pad, pad, pad, cv2.BORDER_REPLICATE)
        faces = self.app.get(padded)
        
        if len(faces) > 0:
            if len(faces) > 1:
                faces = sorted(faces, key=lambda x: (x.bbox[2]-x.bbox[0])*(x.bbox[3]-x.bbox[1]), reverse=True)
            return faces[0].embedding
        
        # æ–¹æ¡ˆ2ï¼šå¦‚æœè¿˜æ˜¯æ£€æµ‹ä¸åˆ°ï¼Œå°è¯•ç›´æ¥æå–ç‰¹å¾ï¼ˆç²¾åº¦è¾ƒä½ï¼Œä½†ä¿è¯æœ‰è¾“å‡ºï¼‰
        try:
            rec_model = self.app.models.get('recognition')
            if rec_model is not None:
                face_resized = cv2.resize(face_crop, (112, 112))
                embedding = rec_model.get_feat([face_resized])
                return embedding[0]
        except Exception:
            pass
        
        return None

    def _extract_embedding(self, image_bgr: np.ndarray) -> Optional[np.ndarray]:
        """
        ä» BGR å›¾åƒæå–äººè„¸ç‰¹å¾å‘é‡ï¼ˆç”¨äºå®Œæ•´å›¾åƒï¼‰
        
        Args:
            image_bgr: BGR æ ¼å¼çš„å›¾åƒ (OpenCV æ ¼å¼)
        
        Returns:
            512ç»´ç‰¹å¾å‘é‡ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°äººè„¸åˆ™è¿”å› None
        """
        faces = self.app.get(image_bgr)
        
        if len(faces) == 0:
            return None
        
        # å¦‚æœæœ‰å¤šä¸ªäººè„¸ï¼Œé€‰æ‹©æœ€å¤§çš„
        if len(faces) > 1:
            faces = sorted(faces, key=lambda x: (x.bbox[2]-x.bbox[0])*(x.bbox[3]-x.bbox[1]), reverse=True)
        
        return faces[0].embedding

    def _extract_embedding_from_file(self, image_path: str) -> Optional[np.ndarray]:
        """ä»å›¾ç‰‡æ–‡ä»¶æå–ç‰¹å¾"""
        import cv2
        img = cv2.imread(image_path)
        if img is None:
            return None
        return self._extract_embedding(img)

    def _compute_similarity(self, emb1: np.ndarray, emb2: np.ndarray) -> float:
        """è®¡ç®—ä¸¤ä¸ªç‰¹å¾å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œè¿”å› 0-1 èŒƒå›´"""
        emb1 = emb1 / np.linalg.norm(emb1)
        emb2 = emb2 / np.linalg.norm(emb2)
        sim = np.dot(emb1, emb2)
        return (sim + 1) / 2  # æ˜ å°„åˆ° 0-1

    def load_photo_database(self, photo_folder: str) -> int:
        """
        åŠ è½½äººè„¸ç…§ç‰‡åº“
        
        æ”¯æŒä¸¤ç§ç›®å½•ç»“æ„:
        
        ç»“æ„1 - æ¯äººä¸€å¼ ç…§ç‰‡:
            photo_folder/
            â”œâ”€â”€ å¼ ä¸‰.jpg    <- æ–‡ä»¶åä½œä¸ºäººå
            â”œâ”€â”€ æå››.png
            â””â”€â”€ ç‹äº”.jpeg
        
        ç»“æ„2 - æ¯äººå¤šå¼ ç…§ç‰‡:
            photo_folder/
            â”œâ”€â”€ å¼ ä¸‰/        <- æ–‡ä»¶å¤¹åä½œä¸ºäººå
            â”‚   â”œâ”€â”€ img1.jpg
            â”‚   â””â”€â”€ img2.jpg
            â”œâ”€â”€ æå››/
            â”‚   â””â”€â”€ photo.jpg
            â””â”€â”€ ç‹äº”.png     <- ä¹Ÿå¯ä»¥æ··åˆä½¿ç”¨
        
        Args:
            photo_folder: ç…§ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
        
        Returns:
            int: æˆåŠŸåŠ è½½çš„äººæ•°
        """
        import cv2
        
        folder = Path(photo_folder)
        if not folder.exists():
            print(f"âŒ ç…§ç‰‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {photo_folder}")
            return 0
        
        self.face_database.clear()
        self.face_all_embeddings.clear()
        
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å­ç›®å½•ï¼ˆå¤šå¼ ç…§ç‰‡æ¨¡å¼ï¼‰
        subdirs = [d for d in folder.iterdir() if d.is_dir()]
        
        if subdirs:
            # æ¨¡å¼2: å­ç›®å½•æ¨¡å¼
            print(f"ğŸ“‚ æ£€æµ‹åˆ°å­ç›®å½•æ¨¡å¼ï¼Œæ¯ä¸ªå­ç›®å½•ä»£è¡¨ä¸€ä¸ªäºº")
            for subdir in subdirs:
                person_name = subdir.name
                embeddings = []
                
                for img_file in subdir.iterdir():
                    if img_file.suffix.lower() not in image_extensions:
                        continue
                    
                    emb = self._extract_embedding_from_file(str(img_file))
                    if emb is not None:
                        embeddings.append(emb)
                
                if embeddings:
                    # è®¡ç®—å¹³å‡ç‰¹å¾
                    avg_emb = np.mean(embeddings, axis=0)
                    avg_emb = avg_emb / np.linalg.norm(avg_emb)
                    self.face_database[person_name] = avg_emb
                    self.face_all_embeddings[person_name] = embeddings
                    print(f"   âœ… {person_name}: {len(embeddings)} å¼ ç…§ç‰‡")
                else:
                    print(f"   âš ï¸  {person_name}: æœªæå–åˆ°äººè„¸ç‰¹å¾")
        
        # ä¹Ÿå¤„ç†æ ¹ç›®å½•ä¸‹çš„å›¾ç‰‡ï¼ˆæ¨¡å¼1æˆ–æ··åˆæ¨¡å¼ï¼‰
        root_images = [f for f in folder.iterdir() 
                       if f.is_file() and f.suffix.lower() in image_extensions]
        
        if root_images:
            print(f"ğŸ“· å¤„ç†æ ¹ç›®å½•ä¸‹çš„ {len(root_images)} å¼ ç…§ç‰‡")
            for img_file in root_images:
                person_name = img_file.stem  # æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºäººå
                
                emb = self._extract_embedding_from_file(str(img_file))
                if emb is not None:
                    self.face_database[person_name] = emb
                    self.face_all_embeddings[person_name] = [emb]
                    print(f"   âœ… {person_name}")
                else:
                    print(f"   âš ï¸  {person_name}: æœªæ£€æµ‹åˆ°äººè„¸")
        
        print(f"\nğŸ“Š ç…§ç‰‡åº“åŠ è½½å®Œæˆ: {len(self.face_database)} äºº")
        return len(self.face_database)

    def match(self, face_image: np.ndarray) -> MatchResult:
        """
        åŒ¹é…äººè„¸ï¼Œæ‰¾å‡ºæœ€ç›¸ä¼¼çš„äºº
        
        Args:
            face_image: äººè„¸å›¾åƒ (BGR æ ¼å¼ï¼ŒOpenCV)ï¼Œå·²è£å‰ªçš„äººè„¸åŒºåŸŸ
        
        Returns:
            MatchResult: åŒ¹é…ç»“æœ
        """
        if len(self.face_database) == 0:
            return MatchResult(name="æœªçŸ¥äººå‘˜", similarity=0.0, all_similarities=None)
        
        # ä»è£å‰ªçš„äººè„¸ä¸­æå–ç‰¹å¾
        query_emb = self._extract_embedding_from_crop(face_image)
        
        if query_emb is None:
            return MatchResult(name="æœªçŸ¥äººå‘˜", similarity=0.0, all_similarities=None)
        
        # ä¸æ•°æ®åº“åŒ¹é…ï¼Œæ‰¾æœ€ä¼˜
        all_similarities = {}
        for name, db_emb in self.face_database.items():
            sim = self._compute_similarity(query_emb, db_emb)
            all_similarities[name] = sim
        
        best_name = max(all_similarities, key=all_similarities.get)
        best_sim = all_similarities[best_name]
        
        # ç½®ä¿¡åº¦é˜ˆå€¼åˆ¤æ–­
        if best_sim < self.threshold:
            return MatchResult(
                name="æœªçŸ¥äººå‘˜",
                similarity=best_sim,
                all_similarities=all_similarities
            )
        
        return MatchResult(
            name=best_name,
            similarity=best_sim,
            all_similarities=all_similarities
        )

    def match_embedding(self, embedding: np.ndarray) -> MatchResult:
        """
        ä½¿ç”¨é¢„å…ˆæå–çš„ç‰¹å¾å‘é‡è¿›è¡ŒåŒ¹é…
        
        Args:
            embedding: 512ç»´äººè„¸ç‰¹å¾å‘é‡
        
        Returns:
            MatchResult: åŒ¹é…ç»“æœ
        """
        if len(self.face_database) == 0:
            return MatchResult(name="æœªçŸ¥äººå‘˜", similarity=0.0, all_similarities=None)
        
        all_similarities = {}
        for name, db_emb in self.face_database.items():
            sim = self._compute_similarity(embedding, db_emb)
            all_similarities[name] = sim
        
        best_name = max(all_similarities, key=all_similarities.get)
        best_sim = all_similarities[best_name]
        
        # ç½®ä¿¡åº¦é˜ˆå€¼åˆ¤æ–­
        if best_sim < self.threshold:
            return MatchResult(
                name="æœªçŸ¥äººå‘˜",
                similarity=best_sim,
                all_similarities=all_similarities
            )
        
        return MatchResult(
            name=best_name,
            similarity=best_sim,
            all_similarities=all_similarities
        )

    def add_person(self, name: str, images: List[np.ndarray]) -> bool:
        """
        åŠ¨æ€æ·»åŠ æ–°äººåˆ°æ•°æ®åº“
        
        Args:
            name: äººå
            images: BGR æ ¼å¼çš„äººè„¸å›¾åƒåˆ—è¡¨
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        embeddings = []
        for img in images:
            emb = self._extract_embedding(img)
            if emb is not None:
                embeddings.append(emb)
        
        if not embeddings:
            print(f"âš ï¸  æ— æ³•ä¸º {name} æå–ä»»ä½•äººè„¸ç‰¹å¾")
            return False
        
        avg_emb = np.mean(embeddings, axis=0)
        avg_emb = avg_emb / np.linalg.norm(avg_emb)
        
        self.face_database[name] = avg_emb
        self.face_all_embeddings[name] = embeddings
        
        print(f"âœ… å·²æ·»åŠ  {name}ï¼Œå…± {len(embeddings)} å¼ ç…§ç‰‡")
        return True

    def save_database(self, save_path: str) -> None:
        """ä¿å­˜äººè„¸æ•°æ®åº“åˆ°æ–‡ä»¶"""
        if len(self.face_database) == 0:
            raise ValueError("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
        
        data = {
            'names': list(self.face_database.keys()),
            'embeddings': np.array([self.face_database[name] for name in self.face_database.keys()])
        }
        np.savez(save_path, **data)
        print(f"âœ… äººè„¸æ•°æ®åº“å·²ä¿å­˜åˆ°: {save_path}")

    def load_database(self, load_path: str) -> int:
        """ä»æ–‡ä»¶åŠ è½½äººè„¸æ•°æ®åº“"""
        if not os.path.exists(load_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {load_path}")
        
        data = np.load(load_path, allow_pickle=True)
        names = data['names']
        embeddings = data['embeddings']
        
        self.face_database = {name: emb for name, emb in zip(names, embeddings)}
        self.face_all_embeddings = {name: [emb] for name, emb in zip(names, embeddings)}
        
        print(f"âœ… å·²åŠ è½½ {len(self.face_database)} äººçš„äººè„¸æ•°æ®")
        return len(self.face_database)
