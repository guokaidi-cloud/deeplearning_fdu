#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOv8 äººè„¸æ£€æµ‹å™¨ + InsightFace äººè„¸è¯†åˆ«
ä½¿ç”¨ YOLO æ£€æµ‹äººè„¸ï¼ŒInsightFace åŒ¹é…è¯†åˆ«æœ€ç›¸ä¼¼çš„äºº
"""

import cv2
import numpy as np
from pathlib import Path
from ultralytics import YOLO
import argparse
import time
import sys
from collections import defaultdict
from typing import Optional

# PIL ç”¨äºä¸­æ–‡å­—ä½“æ”¯æŒ
try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

sys.path.append(str(Path(__file__).parent))

from face_detector import YOLOFaceDetector

# å¯¼å…¥ InsightFace åŒ¹é…å™¨
try:
    from insightface_matcher import InsightFaceMatcher, INSIGHTFACE_AVAILABLE
except ImportError:
    try:
        sys.path.insert(0, str(Path(__file__).parent))
        from insightface_matcher import InsightFaceMatcher, INSIGHTFACE_AVAILABLE
    except ImportError:
        INSIGHTFACE_AVAILABLE = False
        InsightFaceMatcher = None

# ======================== é…ç½® ========================
CHINESE_FONT_PATHS = [
    "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
    "/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc",
    "/usr/share/fonts/wqy-microhei/wqy-microhei.ttc",
    "C:/Windows/Fonts/msyh.ttc",
    "/System/Library/Fonts/PingFang.ttc",
]

DEFAULT_SIMILARITY_THRESHOLD = 0.15

# åŠ è½½ä¸­æ–‡å­—ä½“ï¼ˆç”¨äºç‹¬ç«‹å‡½æ•°ï¼‰
def _load_chinese_font(size=20):
    """åŠ è½½ä¸­æ–‡å­—ä½“"""
    if not PIL_AVAILABLE:
        return None
    for font_path in CHINESE_FONT_PATHS:
        if Path(font_path).exists():
            try:
                return ImageFont.truetype(font_path, size)
            except Exception:
                continue
    return None

def draw_text_pil(image, text, position, font_color=(255, 255, 255), bg_color=(0, 128, 0), font_size=20):
    """
    ä½¿ç”¨ PIL åœ¨å›¾åƒä¸Šç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬
    
    Args:
        image: OpenCVå›¾åƒ (BGR)
        text: è¦ç»˜åˆ¶çš„æ–‡æœ¬
        position: æ–‡æœ¬ä½ç½® (x, y) - å·¦ä¸Šè§’
        font_color: å­—ä½“é¢œè‰² (R, G, B)
        bg_color: èƒŒæ™¯é¢œè‰² (R, G, B)
        font_size: å­—ä½“å¤§å°
    
    Returns:
        å¤„ç†åçš„å›¾åƒ
    """
    if not PIL_AVAILABLE:
        # å›é€€åˆ° OpenCV
        cv2.putText(image, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, font_color[::-1], 1)
        return image
    
    font = _load_chinese_font(font_size)
    if font is None:
        cv2.putText(image, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, font_color[::-1], 1)
        return image
    
    # è½¬æ¢ä¸º PIL å›¾åƒ
    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(pil_image)
    
    x, y = position
    
    # è·å–æ–‡æœ¬è¾¹ç•Œæ¡†
    bbox = draw.textbbox((0, 0), text, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]
    
    # ç»˜åˆ¶èƒŒæ™¯çŸ©å½¢
    padding = 3
    draw.rectangle(
        [(x, y), (x + text_width + padding * 2, y + text_height + padding * 2)],
        fill=bg_color
    )
    
    # ç»˜åˆ¶æ–‡æœ¬
    draw.text((x + padding, y + padding), text, font=font, fill=font_color)
    
    # è½¬å› OpenCV æ ¼å¼
    return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)


def get_chinese_font(font_size=20):
    """
    è·å–å¯ç”¨çš„ä¸­æ–‡å­—ä½“
    
    Args:
        font_size (int): å­—ä½“å¤§å°
        
    Returns:
        ImageFont: å­—ä½“å¯¹è±¡ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ä½“åˆ™è¿”å›é»˜è®¤å­—ä½“
    """
    if not PIL_AVAILABLE:
        return None
    
    for font_path in CHINESE_FONT_PATHS:
        if Path(font_path).exists():
            try:
                return ImageFont.truetype(font_path, font_size)
            except IOError:
                continue
    
    print("âš ï¸  æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨é»˜è®¤å­—ä½“ï¼ˆä¸­æ–‡å¯èƒ½æ˜¾ç¤ºä¸ºæ–¹å—ï¼‰")
    return ImageFont.load_default()


def check_and_download_model(model_path, model_name='yolov8n-face'):
    """
    æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½
    
    Args:
        model_path (Path): æ¨¡å‹æ–‡ä»¶è·¯å¾„
        model_name (str): æ¨¡å‹åç§°
        
    Returns:
        bool: æ¨¡å‹æ˜¯å¦å¯ç”¨
    """
    if model_path.exists():
        print(f"âœ… æ‰¾åˆ°äººè„¸æ£€æµ‹æ¨¡å‹: {model_path}")
        return True
    
    print(f"âš ï¸  æœªæ‰¾åˆ°äººè„¸æ£€æµ‹æ¨¡å‹: {model_path}")
    print(f"ğŸ”„ å¼€å§‹è‡ªåŠ¨ä¸‹è½½ {model_name} æ¨¡å‹...")
    
    try:
        # å¯¼å…¥ä¸‹è½½è„šæœ¬
        from scripts.download_face_models import download_file
        
        # äººè„¸æ£€æµ‹æ¨¡å‹ä¸‹è½½é“¾æ¥
        face_model_urls = {
            'yolov8n-face': 'https://github.com/lindevs/yolov8-face/releases/latest/download/yolov8n-face-lindevs.pt',
            'yolov12l-face': 'https://github.com/akanametov/yolov8-face/releases/download/v0.0.0/yolov12l-face.pt',
        }
        
        if model_name not in face_model_urls:
            print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
            return False
        
        # åˆ›å»ºæ¨¡å‹ç›®å½•
        model_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¸‹è½½æ¨¡å‹
        download_file(face_model_urls[model_name], str(model_path))
        
        if model_path.exists() and model_path.stat().st_size > 1024 * 1024:
            print(f"âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ: {model_path}")
            return True
        else:
            print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥æˆ–æ–‡ä»¶æŸå")
            return False
            
    except Exception as e:
        print(f"âŒ è‡ªåŠ¨ä¸‹è½½å¤±è´¥: {e}")
        print(f"ğŸ’¡ è¯·æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°: {model_path}")
        if model_name == 'yolov8n-face':
            print(f"   ä¸‹è½½é“¾æ¥: https://github.com/lindevs/yolov8-face/releases/latest/download/yolov8n-face-lindevs.pt")
        else:
            print(f"   ä¸‹è½½é“¾æ¥: https://huggingface.co/Bingsu/adetailer/tree/main")
        return False


class YOLOSpecializedFaceDetector(YOLOFaceDetector):
    """
    ä¸“é—¨çš„YOLOv8äººè„¸æ£€æµ‹å™¨
    ä½¿ç”¨ä¼˜åŒ–çš„äººè„¸æ£€æµ‹æ¨¡å‹ï¼Œæ”¯æŒåŸºäº InsightFace çš„äººè„¸åŒ¹é…è¯†åˆ«å’Œ ByteTrack è·Ÿè¸ª
    """
    
    def __init__(self, model_name='yolov8n-face', conf_threshold=0.3, device='auto', 
                 models_dir='models', model_path=None,
                 # äººè„¸è¯†åˆ«å‚æ•°
                 photo_folder=None, similarity_threshold=DEFAULT_SIMILARITY_THRESHOLD, 
                 insightface_model_name='buffalo_sc',
                 # è·Ÿè¸ªå‚æ•°
                 enable_tracking=False, tracker_type='bytetrack', track_buffer=30):
        """
        åˆå§‹åŒ–ä¸“é—¨çš„äººè„¸æ£€æµ‹å™¨
        
        Args:
            model_name (str): æ¨¡å‹åç§° ('yolov8n-face', 'yolov8s-face', 'yolov12l-face')
            conf_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼
            device (str): è¿è¡Œè®¾å¤‡ (auto/cuda/cpu)
            models_dir (str): æ¨¡å‹ç›®å½•
            model_path (str|None): è‡ªå®šä¹‰æ¨¡å‹è·¯å¾„ï¼ˆä¼˜å…ˆäº model_name/models_dirï¼‰
            photo_folder (str): äººè„¸ç…§ç‰‡åº“æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆç”¨äºäººè„¸è¯†åˆ«ï¼‰
            similarity_threshold (float): ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼ä¸º"æœªçŸ¥äººå‘˜"
            insightface_model_name (str): InsightFaceæ¨¡å‹åç§° (buffalo_l, buffalo_s, buffalo_sc)
            enable_tracking (bool): æ˜¯å¦å¯ç”¨è·Ÿè¸ª
            tracker_type (str): è·Ÿè¸ªå™¨ç±»å‹ ('bytetrack' æˆ– 'botsort')
            track_buffer (int): è·Ÿè¸ªç¼“å†²å¸§æ•°ï¼ˆè½¨è¿¹æœ€å¤§ä¸¢å¤±å¸§æ•°ï¼‰
        """
        self.model_name = model_name
        self.models_dir = Path(models_dir)
        self.chinese_font = None
        self.enable_tracking = enable_tracking
        self.tracker_type = tracker_type
        self.track_buffer = track_buffer
        
        # InsightFace äººè„¸åŒ¹é…å™¨
        self.face_matcher = None
        
        # æ„é€ æ¨¡å‹è·¯å¾„ï¼Œä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰è·¯å¾„
        if model_path:
            model_path = Path(model_path)
            custom_model = True
        else:
            model_path = self.models_dir / f"{model_name}.pt"
            custom_model = False
        
        # æ£€æŸ¥å¹¶ä¸‹è½½/éªŒè¯æ¨¡å‹
        if not model_path.exists():
            if custom_model:
                raise RuntimeError(f"è‡ªå®šä¹‰æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            if not check_and_download_model(model_path, model_name):
                raise RuntimeError(f"æ— æ³•è·å–äººè„¸æ£€æµ‹æ¨¡å‹: {model_name}")
        
        # ä½¿ç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(
            model_path=str(model_path),
            conf_threshold=conf_threshold,
            device=device
        )
        
        # åŠ è½½ä¸­æ–‡å­—ä½“
        if PIL_AVAILABLE:
            self.chinese_font = get_chinese_font(font_size=20)
        
        # åˆå§‹åŒ– InsightFace äººè„¸åŒ¹é…å™¨
        if photo_folder:
            if INSIGHTFACE_AVAILABLE:
                try:
                    # è§£æ device å‚æ•°
                    if device == 'auto':
                        import torch
                        ctx_id = 0 if torch.cuda.is_available() else -1
                    elif device == 'cuda':
                        ctx_id = 0
                    else:
                        ctx_id = -1
                    
                    self.face_matcher = InsightFaceMatcher(
                        photo_folder=photo_folder,
                        threshold=similarity_threshold,
                        model_name=insightface_model_name,
                        ctx_id=ctx_id
                    )
                    print(f"ğŸ‘¥ InsightFaceäººè„¸åŒ¹é…: å·²åŠ è½½ {self.face_matcher.num_people} äºº")
                except Exception as e:
                    print(f"âš ï¸ åˆå§‹åŒ–InsightFaceäººè„¸åŒ¹é…å™¨å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    self.face_matcher = None
            else:
                print("âš ï¸ InsightFace åº“æœªå®‰è£…ï¼Œäººè„¸è¯†åˆ«åŠŸèƒ½ä¸å¯ç”¨")
                print("   å®‰è£…å‘½ä»¤: pip install insightface onnxruntime-gpu")
        
        self.model_path = model_path  # è®°å½•å®é™…ä½¿ç”¨çš„æ¨¡å‹è·¯å¾„
        
        # æ‰“å°åˆå§‹åŒ–ä¿¡æ¯
        print(f"ğŸ¯ ä¸“ä¸šäººè„¸æ£€æµ‹å™¨å·²å°±ç»ª")
        if custom_model:
            print(f"ğŸ“¦ æ¨¡å‹: è‡ªå®šä¹‰ -> {self.model_path}")
        else:
            print(f"ğŸ“¦ æ¨¡å‹: {model_name} -> {self.model_path}")
        print(f"ğŸšï¸  ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
        if enable_tracking:
            print(f"ğŸ”„ è·Ÿè¸ªå™¨: {tracker_type.upper()} (buffer={track_buffer})")
        else:
            print(f"ğŸ”„ è·Ÿè¸ª: å·²ç¦ç”¨")
    
    def load_photo_database(self, photo_folder):
        """
        åŠ è½½äººè„¸ç…§ç‰‡åº“
        
        Args:
            photo_folder (str): ç…§ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
            
        Returns:
            int: åŠ è½½çš„äººæ•°
        """
        if not INSIGHTFACE_AVAILABLE:
            print("âŒ InsightFace åº“æœªå®‰è£…ï¼Œæ— æ³•åŠ è½½äººè„¸åº“")
            return 0
        
        if self.face_matcher is None:
            self.face_matcher = InsightFaceMatcher(threshold=DEFAULT_SIMILARITY_THRESHOLD)
        
        return self.face_matcher.load_photo_database(photo_folder)
    
    def recognize_face_with_bbox(self, full_image, bbox):
        """
        ä½¿ç”¨ InsightFace åŒ¹é…è¯†åˆ«äººè„¸
        
        ç›´æ¥ä½¿ç”¨ YOLO bbox è£å‰ªäººè„¸åŒºåŸŸè¿›è¡Œè¯†åˆ«
        
        Args:
            full_image: å®Œæ•´å›¾åƒ (BGRæ ¼å¼)
            bbox: YOLOæ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡† [x1, y1, x2, y2]
            
        Returns:
            tuple: (å§“å, ç›¸ä¼¼åº¦)
        """
        if self.face_matcher is None:
            return "æœªçŸ¥äººå‘˜", None
        
        try:
            # ç›´æ¥ä½¿ç”¨æ‰¹é‡åŒ¹é…æ–¹æ³•ï¼ˆå•ä¸ª bboxï¼‰
            results = self.face_matcher.match_all_faces_in_image(full_image, [bbox])
            if results:
                result = results[0]
                print(f"ğŸ‘¥ InsightFace åŒ¹é…ç»“æœ: {result.name} ({result.similarity:.2f})")
                return result.name, result.similarity
            return "æœªçŸ¥äººå‘˜", None
        except Exception as e:
            print(f"âš ï¸  äººè„¸è¯†åˆ«å¤±è´¥: {e}")
            return "æœªçŸ¥äººå‘˜", None
    
    def draw_chinese_text(self, image, text, position, font_color=(255, 255, 255), bg_color=(0, 0, 0)):
        """
        åœ¨å›¾åƒä¸Šç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬
        
        Args:
            image: OpenCVå›¾åƒ (BGR)
            text: è¦ç»˜åˆ¶çš„æ–‡æœ¬
            position: æ–‡æœ¬ä½ç½® (x, y)
            font_color: å­—ä½“é¢œè‰² (R, G, B)
            bg_color: èƒŒæ™¯é¢œè‰² (R, G, B)
            
        Returns:
            å¤„ç†åçš„å›¾åƒ
        """
        if not PIL_AVAILABLE or self.chinese_font is None:
            # å¦‚æœPILä¸å¯ç”¨ï¼Œä½¿ç”¨OpenCVç»˜åˆ¶ï¼ˆä¸­æ–‡ä¼šæ˜¾ç¤ºä¸ºæ–¹å—ï¼‰
            cv2.putText(image, text, position, cv2.FONT_HERSHEY_SIMPLEX, 0.6, font_color[::-1], 2)
            return image
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)
        
        x, y = position
        
        # è·å–æ–‡æœ¬è¾¹ç•Œæ¡†
        bbox = draw.textbbox((0, 0), text, font=self.chinese_font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]
        
        # ç»˜åˆ¶èƒŒæ™¯çŸ©å½¢
        padding = 5
        draw.rectangle(
            [(x, y), (x + text_width + padding * 2, y + text_height + padding * 2)],
            fill=bg_color
        )
        
        # ç»˜åˆ¶æ–‡æœ¬
        draw.text((x + padding, y + padding), text, font=self.chinese_font, fill=font_color)
        
        # è½¬å›OpenCVæ ¼å¼
        return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
    
    def detect_and_track(self, image, recognize=True, persist=True):
        """
        ä½¿ç”¨YOLOå†…ç½®çš„ByteTrack/BotSORTè¿›è¡Œæ£€æµ‹å’Œè·Ÿè¸ª
        
        Args:
            image: è¾“å…¥å›¾åƒ
            recognize (bool): æ˜¯å¦è¿›è¡Œäººè„¸è¯†åˆ«ï¼ˆä½¿ç”¨ InsightFace åŒ¹é…ï¼‰
            persist (bool): æ˜¯å¦æŒä¹…åŒ–è·Ÿè¸ªIDï¼ˆè·¨å¸§ä¿æŒIDï¼‰
            
        Returns:
            list: è·Ÿè¸ªç»“æœåˆ—è¡¨ï¼ŒåŒ…å«track_id
        """
        if isinstance(image, np.ndarray):
            original_image = image.copy()
            original_shape = image.shape[:2]
        else:
            original_image = np.array(image)
            original_shape = original_image.shape[:2]
        
        # ä½¿ç”¨YOLOçš„trackæ–¹æ³•è¿›è¡Œè·Ÿè¸ª
        results = self.model.track(
            original_image, 
            conf=self.conf_threshold,
            persist=persist,
            tracker=f"{self.tracker_type}.yaml",
            verbose=False
        )
        
        tracked_faces = []
        
        # å…ˆæ”¶é›†æ‰€æœ‰æ£€æµ‹æ¡†
        for result in results:
            boxes = result.boxes
            if boxes is not None and len(boxes) > 0:
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = float(box.conf[0].cpu().numpy())
                    
                    track_id = None
                    if box.id is not None:
                        track_id = int(box.id[0].cpu().numpy())
                    
                    x1_int = max(0, int(x1))
                    y1_int = max(0, int(y1))
                    x2_int = min(original_shape[1], int(x2))
                    y2_int = min(original_shape[0], int(y2))
                    
                    face_info = {
                        'bbox': [x1_int, y1_int, x2_int, y2_int],
                        'confidence': confidence,
                        'track_id': track_id,
                        'name': "æœªçŸ¥äººå‘˜",
                        'similarity': None
                    }
                    tracked_faces.append(face_info)
        
        # æ‰¹é‡è¿›è¡Œäººè„¸è¯†åˆ«ï¼ˆæ¯å¸§åªè°ƒç”¨ä¸€æ¬¡ InsightFaceï¼‰
        if recognize and self.face_matcher is not None and len(tracked_faces) > 0:
            # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„äººè„¸æ¡†
            valid_indices = []
            valid_bboxes = []
            for i, face in enumerate(tracked_faces):
                x1, y1, x2, y2 = face['bbox']
                if (x2 - x1) > 20 and (y2 - y1) > 20:
                    valid_indices.append(i)
                    valid_bboxes.append(face['bbox'])
            
            if valid_bboxes:
                try:
                    # æ‰¹é‡åŒ¹é…æ‰€æœ‰äººè„¸
                    match_results = self.face_matcher.match_all_faces_in_image(
                        original_image, valid_bboxes
                    )
                    # å°†ç»“æœå†™å›
                    for idx, match_result in zip(valid_indices, match_results):
                        tracked_faces[idx]['name'] = match_result.name
                        tracked_faces[idx]['similarity'] = match_result.similarity
                        print(f"ğŸ‘¥ InsightFace åŒ¹é…ç»“æœ: {match_result.name} ({match_result.similarity:.2f})")
                except Exception as e:
                    print(f"âš ï¸  æ‰¹é‡äººè„¸è¯†åˆ«å¤±è´¥: {e}")
        
        return tracked_faces
    
    def detect_faces(self, image, visualize=True, recognize=True):
        """
        æ£€æµ‹å›¾ç‰‡ä¸­çš„äººè„¸ï¼ˆæ”¯æŒ InsightFace äººè„¸åŒ¹é…è¯†åˆ«ï¼‰
        
        Args:
            image: è¾“å…¥å›¾åƒ
            visualize (bool): æ˜¯å¦å¯è§†åŒ–æ£€æµ‹ç»“æœ
            recognize (bool): æ˜¯å¦è¿›è¡Œäººè„¸è¯†åˆ«ï¼ˆä½¿ç”¨ InsightFace åŒ¹é…ï¼‰
            
        Returns:
            tuple: (æ£€æµ‹ç»“æœ, å¯è§†åŒ–å›¾åƒ)
        """
        # ä¿å­˜åŸå§‹å›¾åƒå°ºå¯¸
        if isinstance(image, np.ndarray):
            original_image = image.copy()
            original_shape = image.shape[:2]  # (height, width)
        else:
            original_image = np.array(image)
            original_shape = original_image.shape[:2]
        
        # è¿è¡Œæ¨ç†
        results = self.model(original_image, conf=self.conf_threshold, verbose=False)
        
        faces = []
        # ç¡®ä¿ä½¿ç”¨åŸå§‹åˆ†è¾¨ç‡çš„å›¾åƒè¿›è¡Œå¯è§†åŒ–
        vis_image = original_image.copy()
        
        # å…ˆæ”¶é›†æ‰€æœ‰æ£€æµ‹æ¡†
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = box.conf[0].cpu().numpy()
                    
                    x1_int = max(0, int(x1))
                    y1_int = max(0, int(y1))
                    x2_int = min(original_shape[1], int(x2))
                    y2_int = min(original_shape[0], int(y2))
                    
                    face_info = {
                        'bbox': [x1_int, y1_int, x2_int, y2_int],
                        'confidence': float(confidence),
                        'name': "æœªçŸ¥äººå‘˜",
                        'similarity': None
                    }
                    faces.append(face_info)
        
        # æ‰¹é‡è¿›è¡Œäººè„¸è¯†åˆ«ï¼ˆæ¯å¸§åªè°ƒç”¨ä¸€æ¬¡ InsightFaceï¼‰
        if recognize and self.face_matcher is not None and len(faces) > 0:
            valid_indices = []
            valid_bboxes = []
            for i, face in enumerate(faces):
                x1, y1, x2, y2 = face['bbox']
                if (x2 - x1) > 20 and (y2 - y1) > 20:
                    valid_indices.append(i)
                    valid_bboxes.append(face['bbox'])
            
            if valid_bboxes:
                try:
                    match_results = self.face_matcher.match_all_faces_in_image(
                        original_image, valid_bboxes
                    )
                    for idx, match_result in zip(valid_indices, match_results):
                        faces[idx]['name'] = match_result.name
                        faces[idx]['similarity'] = match_result.similarity
                except Exception as e:
                    print(f"âš ï¸  æ‰¹é‡äººè„¸è¯†åˆ«å¤±è´¥: {e}")
        
        # å¯è§†åŒ–
        if visualize:
            for face_info in faces:
                x1_int, y1_int, x2_int, y2_int = face_info['bbox']
                confidence = face_info['confidence']
                name = face_info['name']
                similarity = face_info['similarity']
                is_known = name != "æœªçŸ¥äººå‘˜"
                
                # æ ¹æ®æ˜¯å¦è¯†åˆ«æˆåŠŸé€‰æ‹©é¢œè‰²
                box_color = (0, 255, 0) if is_known else (0, 255, 255)  # ç»¿è‰²=å·²è¯†åˆ«, é»„è‰²=æœªè¯†åˆ«
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(vis_image, (x1_int, y1_int), (x2_int, y2_int), box_color, 2)
                
                # æ„å»ºæ ‡ç­¾æ–‡æœ¬
                if is_known and similarity is not None:
                    label = f'{name} ({similarity:.2f})'
                elif is_known:
                    label = f'{name}'
                else:
                    label = f'Face: {confidence:.3f}'
                
                # ç»˜åˆ¶æ ‡ç­¾ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
                label_y = max(0, y1_int - 28)
                vis_image = self.draw_chinese_text(
                    vis_image, 
                    label, 
                    (x1_int, label_y),
                    font_color=(0, 0, 0),
                    bg_color=box_color
                )
        
        return faces, vis_image


def process_video_with_yolov8(detector, video_path, output_path=None, show_video=False, 
                              max_frames=None, start_time=None, end_time=None, save_faces=True,
                              save_interval_sec=5.0, enable_recognition=True, enable_tracking=True):
    """
    ä½¿ç”¨YOLOv8å¤„ç†è§†é¢‘æ–‡ä»¶è¿›è¡Œäººè„¸æ£€æµ‹ã€è¯†åˆ«å’Œè·Ÿè¸ª
    
    Args:
        detector: YOLOv8äººè„¸æ£€æµ‹å™¨å®ä¾‹
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        show_video: æ˜¯å¦æ˜¾ç¤ºè§†é¢‘
        max_frames: æœ€å¤§å¤„ç†å¸§æ•°
        start_time: å¼€å§‹æ—¶é—´
        end_time: ç»“æŸæ—¶é—´
        save_faces (bool): æ˜¯å¦ä¿å­˜è£å‰ªçš„äººè„¸åˆ°dataç›®å½•
        save_interval_sec (float): ä¿å­˜äººè„¸çš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰ï¼Œç”¨äºé™é¢‘ä¿å­˜
        enable_recognition (bool): æ˜¯å¦å¯ç”¨äººè„¸è¯†åˆ«ï¼ˆä½¿ç”¨ InsightFace åŒ¹é…ï¼‰
        enable_tracking (bool): æ˜¯å¦å¯ç”¨è·Ÿè¸ª (ByteTrack/BotSORT)
    """
    print(f"ğŸ¥ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
    if enable_recognition and hasattr(detector, 'face_matcher') and detector.face_matcher:
        recognizer_name = type(detector.face_matcher).__name__
        print(f"ğŸ‘¥ äººè„¸åŒ¹é…: å·²å¯ç”¨ ({recognizer_name})ï¼Œæ•°æ®åº“ä¸­æœ‰ {detector.face_matcher.num_people} äºº")
    
    # æ£€æŸ¥è·Ÿè¸ªåŠŸèƒ½
    tracking_enabled = enable_tracking and hasattr(detector, 'enable_tracking') and detector.enable_tracking
    if tracking_enabled:
        tracker_type = getattr(detector, 'tracker_type', 'bytetrack')
        print(f"ğŸ”„ è·Ÿè¸ª: å·²å¯ç”¨ ({tracker_type.upper()})")
    else:
        print(f"ğŸ”„ è·Ÿè¸ª: å·²ç¦ç”¨")
    
    # åˆ›å»ºdataç›®å½•ç”¨äºä¿å­˜äººè„¸
    if save_faces:
        data_dir = Path(video_path).parent / 'data'
        data_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ äººè„¸å°†ä¿å­˜åˆ°: {data_dir}")

    # ä»…æ£€æµ‹ä¸ä¿å­˜ï¼Œä¸åšè·Ÿè¸ª
    
    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        return
    
    # è·å–è§†é¢‘å±æ€§
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    
    print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}FPS, æ€»å¸§æ•°={total_frames}, æ—¶é•¿={duration:.1f}ç§’")
    
    # è§£ææ—¶é—´å‚æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä¸opencv_face_detectorä¿æŒä¸€è‡´ï¼‰
    start_frame = 0
    end_frame = total_frames
    
    if start_time:
        try:
            if ':' in start_time:
                parts = start_time.split(':')
                if len(parts) == 3:  # HH:MM:SS
                    hours, minutes, seconds = map(float, parts)
                    start_seconds = hours * 3600 + minutes * 60 + seconds
                elif len(parts) == 2:  # MM:SS
                    minutes, seconds = map(float, parts)
                    start_seconds = minutes * 60 + seconds
            else:
                start_seconds = float(start_time)
            
            start_frame = int(start_seconds * fps)
            start_frame = max(0, min(start_frame, total_frames - 1))
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            print(f"â© è·³è½¬åˆ°å¼€å§‹æ—¶é—´: {start_seconds:.1f}ç§’ (ç¬¬{start_frame}å¸§)")
        except:
            print(f"âš ï¸  æ— æ•ˆçš„å¼€å§‹æ—¶é—´æ ¼å¼: {start_time}")
    
    if end_time:
        try:
            if ':' in end_time:
                parts = end_time.split(':')
                if len(parts) == 3:  # HH:MM:SS
                    hours, minutes, seconds = map(float, parts)
                    end_seconds = hours * 3600 + minutes * 60 + seconds
                elif len(parts) == 2:  # MM:SS
                    minutes, seconds = map(float, parts)
                    end_seconds = minutes * 60 + seconds
            else:
                end_seconds = float(end_time)
                
            end_frame = int(end_seconds * fps)
            end_frame = max(start_frame, min(end_frame, total_frames))
            print(f"â¹ï¸  ç»“æŸæ—¶é—´: {end_seconds:.1f}ç§’ (ç¬¬{end_frame}å¸§)")
        except:
            print(f"âš ï¸  æ— æ•ˆçš„ç»“æŸæ—¶é—´æ ¼å¼: {end_time}")
    
    # è®¡ç®—å¤„ç†å¸§æ•°
    process_frames = end_frame - start_frame
    if max_frames:
        process_frames = min(process_frames, max_frames)
    
    # è®¾ç½®è§†é¢‘å†™å…¥å™¨
    def _create_writer(path: Path, fps: int, size):
        """å°è¯•å¤šç§ç¼–ç ï¼Œæå‡æµè§ˆå™¨å¯æ’­æ”¾æ€§ï¼Œå¹¶ç»™å‡ºæ—¥å¿—"""
        width, height = size
        codec_candidates = [
            ("avc1", "H.264 (æµè§ˆå™¨å…¼å®¹æ€§å¥½ï¼Œéœ€ç³»ç»Ÿæ”¯æŒ)"),
            ("mp4v", "MPEG-4 Part 2 (å…¼å®¹æ€§ä¸€èˆ¬)"),
            ("XVID", "XVID (å¤‡ç”¨)"),
        ]
        for fourcc_tag, desc in codec_candidates:
            fourcc = cv2.VideoWriter_fourcc(*fourcc_tag)
            writer = cv2.VideoWriter(str(path), fourcc, fps, (width, height))
            if writer.isOpened():
                print(f"âœ… ä½¿ç”¨ç¼–ç  {fourcc_tag} - {desc}")
                return writer, fourcc_tag
            else:
                print(f"âš ï¸ åˆ›å»ºå†™å…¥å™¨å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç¼–ç : {fourcc_tag}")
        return None, None

    writer = None
    if output_path:
        writer, used_codec = _create_writer(output_path, fps, (width, height))
        if writer is None:
            print("âŒ æ— æ³•åˆ›å»ºä»»ä½•å¯ç”¨çš„è§†é¢‘å†™å…¥å™¨ï¼Œåœæ­¢å¤„ç†")
            return
        print(f"ğŸ“ è¾“å‡ºè§†é¢‘: {output_path}")
        print(f"ğŸ“ è¾“å‡ºåˆ†è¾¨ç‡: {width}x{height}, FPS: {fps}, ç¼–ç : {used_codec}")
    
    # å¤„ç†ç»Ÿè®¡
    processed_frames = 0
    total_faces = 0
    process_start_time = time.time()
    last_save_time = -1e9  # æ§åˆ¶ä¿å­˜é¢‘ç‡çš„æ—¶é—´æˆ³
    track_save_counts = defaultdict(int)  # ç”¨äºæŒ‰track_idä¿å­˜è®¡æ•°
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # è·å–å½“å‰å¸§ä½ç½®
            current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
            current_time_sec = current_frame / fps if fps > 0 else 0
            
            # æ£€æŸ¥å¤„ç†é™åˆ¶
            if processed_frames >= process_frames:
                break
                
            if max_frames and processed_frames >= max_frames:
                print(f"â¹ï¸  å·²è¾¾åˆ°æœ€å¤§å¤„ç†å¸§æ•°: {max_frames}")
                break
            
            # æ£€æµ‹äººè„¸ï¼ˆæ ¹æ®æ˜¯å¦å¯ç”¨è·Ÿè¸ªé€‰æ‹©ä¸åŒæ–¹æ³•ï¼‰
            if tracking_enabled:
                # ä½¿ç”¨YOLOå†…ç½®çš„ByteTrack/BotSORTè·Ÿè¸ª
                faces = detector.detect_and_track(frame, recognize=enable_recognition, persist=True)
            else:
                # ä»…æ£€æµ‹ï¼Œä¸è·Ÿè¸ª
                faces, _ = detector.detect_faces(frame, visualize=False, recognize=enable_recognition)
            
            total_faces += len(faces)
            
            # ç»Ÿè®¡è¯†åˆ«ç»“æœ
            recognized_names = [f['name'] for f in faces if f.get('name') and f['name'] != "æœªçŸ¥äººå‘˜"]
            
            # è‡ªå®šä¹‰å¯è§†åŒ–ï¼ˆæ”¯æŒè·Ÿè¸ªIDæ˜¾ç¤ºï¼‰
            vis_frame = frame.copy()
            for face in faces:
                x1, y1, x2, y2 = face['bbox']
                confidence = face['confidence']
                name = face.get('name', 'æœªçŸ¥äººå‘˜')
                track_id = face.get('track_id', None)
                is_known = name != "æœªçŸ¥äººå‘˜"
                
                # æ ¹æ®æ˜¯å¦è¯†åˆ«æˆåŠŸé€‰æ‹©é¢œè‰²
                if tracking_enabled and track_id is not None:
                    # è·Ÿè¸ªæ¨¡å¼ï¼šä½¿ç”¨track_idç”Ÿæˆé¢œè‰²
                    color_hash = hash(str(track_id)) % 0xFFFFFF
                    box_color = ((color_hash >> 16) & 0xFF, (color_hash >> 8) & 0xFF, color_hash & 0xFF)
                    # ç¡®ä¿é¢œè‰²è¶³å¤Ÿäº®
                    box_color = tuple(max(c, 50) for c in box_color)
                else:
                    box_color = (0, 255, 0) if is_known else (0, 255, 255)  # ç»¿è‰²=å·²è¯†åˆ«, é»„è‰²=æœªè¯†åˆ«
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(vis_frame, (x1, y1), (x2, y2), box_color, 2)
                
                # æ„å»ºæ ‡ç­¾æ–‡æœ¬ï¼Œä¼˜å…ˆæ˜¾ç¤ºå§“å
                if tracking_enabled and track_id is not None:
                    if is_known:
                        label = f'{name} | ID:{track_id} ({confidence:.2f})'
                    else:
                        label = f'ID:{track_id} ({confidence:.2f})'
                else:
                    if is_known:
                        label = f'{name} ({confidence:.2f})'
                    else:
                        label = f'Face ({confidence:.2f})'
                
                # ç»˜åˆ¶æ ‡ç­¾ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
                label_y = max(0, y1 - 28)
                vis_frame = draw_text_pil(
                    vis_frame, label, (x1, label_y),
                    font_color=(0, 0, 0), 
                    bg_color=box_color,
                    font_size=18
                )

            # ç¡®ä¿vis_frameçš„åˆ†è¾¨ç‡ä¸åŸå§‹frameä¸€è‡´
            if vis_frame.shape[:2] != frame.shape[:2]:
                print(f"âš ï¸  è­¦å‘Š: vis_frameåˆ†è¾¨ç‡ {vis_frame.shape[:2]} ä¸åŸå§‹frameåˆ†è¾¨ç‡ {frame.shape[:2]} ä¸ä¸€è‡´ï¼Œä½¿ç”¨åŸå§‹frame")
                vis_frame = frame.copy()
                # é‡æ–°ç»˜åˆ¶æ£€æµ‹æ¡†
                for face in faces:
                    x1, y1, x2, y2 = face['bbox']
                    confidence = face['confidence']
                    cv2.rectangle(vis_frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)
                    label = f'Face: {confidence:.3f}'
                    label_y = max(0, int(y1) - 28)
                    vis_frame = draw_text_pil(
                        vis_frame, label, (int(x1), label_y),
                        font_color=(0, 0, 0),
                        bg_color=(0, 255, 255),
                        font_size=16
                    )
            
            # ä¿å­˜è£å‰ªçš„äººè„¸
            if save_faces:
                # æŒ‰æ—¶é—´é—´éš”é™é¢‘ä¿å­˜ï¼›è‹¥æœ¬å¸§æœªåˆ°è¾¾ä¿å­˜é—´éš”åˆ™è·³è¿‡ä¿å­˜
                allow_save = (current_time_sec - last_save_time) >= save_interval_sec
                if allow_save:
                    last_save_time = current_time_sec
                    for face_idx, face in enumerate(faces):
                        x1, y1, x2, y2 = face['bbox']
                        confidence = face.get('confidence', 0.0)
                        track_id = face.get('track_id', None)
                        name = face.get('name', 'æœªçŸ¥äººå‘˜')
                        
                        # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                        x1 = max(0, int(x1))
                        y1 = max(0, int(y1))
                        x2 = min(frame.shape[1], int(x2))
                        y2 = min(frame.shape[0], int(y2))
                        
                        # è£å‰ªäººè„¸åŒºåŸŸ
                        face_crop = frame[y1:y2, x1:x2]
                        
                        # åªä¿å­˜æœ‰æ•ˆçš„äººè„¸ï¼ˆå°ºå¯¸ä¸èƒ½å¤ªå°ï¼‰
                        if face_crop.shape[0] > 20 and face_crop.shape[1] > 20:
                            # æ ¹æ®æ˜¯å¦æœ‰track_idå†³å®šä¿å­˜è·¯å¾„
                            if track_id is not None:
                                # æœ‰track_idï¼šæŒ‰IDåˆ†ç›®å½•ä¿å­˜
                                if name != "æœªçŸ¥äººå‘˜":
                                    id_dir = data_dir / f"id_{int(track_id):04d}_{name}"
                                else:
                                    id_dir = data_dir / f"id_{int(track_id):04d}"
                                id_dir.mkdir(parents=True, exist_ok=True)
                                track_save_counts[track_id] += 1
                                face_filename = f"frame_{current_frame:06d}_id_{int(track_id):04d}_n_{track_save_counts[track_id]:04d}.jpg"
                                face_path = id_dir / face_filename
                            else:
                                # æ— track_idï¼šæŒ‰å¸§å·å’Œäººè„¸ç´¢å¼•ä¿å­˜
                                face_filename = f"frame_{current_frame:06d}_face_{face_idx:02d}_conf_{confidence:.3f}.jpg"
                                face_path = data_dir / face_filename
                            cv2.imwrite(str(face_path), face_crop)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            elapsed_time = time.time() - process_start_time
            current_fps = processed_frames / elapsed_time if elapsed_time > 0 else 0
            
            hours = int(current_time_sec // 3600)
            minutes = int((current_time_sec % 3600) // 60)
            seconds = int(current_time_sec % 60)
            
            stats_text = [
                f'Time: {hours:02d}:{minutes:02d}:{seconds:02d} (Frame: {current_frame})',
                f'Progress: {processed_frames+1}/{process_frames}',
                f'Current Faces: {len(faces)}',
                f'Recognized: {len(recognized_names)}',
                f'Processing FPS: {current_fps:.1f}'
            ]
            
            # å¦‚æœæœ‰è¯†åˆ«åˆ°çš„äººï¼Œæ˜¾ç¤ºå§“å
            if recognized_names:
                names_str = ', '.join(recognized_names[:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ªåå­—
                if len(recognized_names) > 3:
                    names_str += f'... (+{len(recognized_names)-3})'
                stats_text.append(f'Names: {names_str}')
            
            for i, text in enumerate(stats_text):
                y_pos = 10 + i * 28
                vis_frame = draw_text_pil(
                    vis_frame, text, (10, y_pos),
                    font_color=(255, 255, 0),
                    bg_color=(0, 0, 0),
                    font_size=18
                )
            
            # ä¿å­˜å¸§
            if writer:
                # ç¡®ä¿vis_frameçš„åˆ†è¾¨ç‡ä¸VideoWriterè®¾ç½®çš„åˆ†è¾¨ç‡ä¸€è‡´
                if vis_frame.shape[:2] != (height, width):
                    vis_frame = cv2.resize(vis_frame, (width, height), interpolation=cv2.INTER_LINEAR)
                writer.write(vis_frame)
            
            # æ˜¾ç¤ºè§†é¢‘
            if show_video:
                cv2.imshow('YOLOv8äººè„¸æ£€æµ‹', vis_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("ğŸ‘¤ ç”¨æˆ·æŒ‰'q'é”®é€€å‡º")
                    break
            
            processed_frames += 1
            
            # å®šæœŸè¾“å‡ºè¿›åº¦
            if processed_frames % 100 == 0:
                progress = (processed_frames / process_frames) * 100
                current_time_str = f"{hours:02d}:{minutes:02d}:{seconds:02d}"
                print(f"ğŸ“ˆ å¤„ç†è¿›åº¦: {processed_frames}/{process_frames} "
                      f"({progress:.1f}%) | æ—¶é—´: {current_time_str} | æ£€æµ‹åˆ°äººè„¸: {total_faces}")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
    
    finally:
        # æ¸…ç†èµ„æº
        cap.release()
        if writer:
            writer.release()
        if show_video:
            cv2.destroyAllWindows()
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    elapsed_time = time.time() - process_start_time
    avg_fps = processed_frames / elapsed_time if elapsed_time > 0 else 0
    
    print(f"\nğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
    print(f"   â±ï¸  å¤„ç†æ—¶é—´: {elapsed_time:.1f}ç§’")
    print(f"   ğŸ“¹ å¤„ç†å¸§æ•°: {processed_frames}")
    print(f"   ğŸ¯ æ£€æµ‹äººè„¸: {total_faces}")
    print(f"   âš¡ å¹³å‡FPS: {avg_fps:.1f}")
    print(f"   ğŸ“ å¹³å‡æ¯å¸§äººè„¸æ•°: {total_faces/processed_frames:.1f}" if processed_frames > 0 else "")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='YOLOv8ä¸“ä¸šäººè„¸æ£€æµ‹å™¨ï¼ˆä½¿ç”¨ InsightFace è¿›è¡Œäººè„¸åŒ¹é…è¯†åˆ«ï¼‰')
    parser.add_argument('--input', type=str, required=True,
                       help='è¾“å…¥è§†é¢‘æˆ–å›¾ç‰‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, 
                       help='è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--show', action='store_true',
                       help='æ˜¾ç¤ºæ£€æµ‹è¿‡ç¨‹')
    parser.add_argument('--max-frames', type=int,
                       help='æœ€å¤§å¤„ç†å¸§æ•° (ç”¨äºæµ‹è¯•)')
    parser.add_argument('--start-time', type=str,
                       help='å¼€å§‹æ—¶é—´ (ç§’æ•°æˆ– HH:MM:SS æ ¼å¼)')
    parser.add_argument('--end-time', type=str, 
                       help='ç»“æŸæ—¶é—´ (ç§’æ•°æˆ– HH:MM:SS æ ¼å¼)')
    parser.add_argument('--model', type=str, default='yolov8n-face',
                       choices=['yolov8n-face', 'yolov12l-face'],
                       help='äººè„¸æ£€æµ‹æ¨¡å‹åç§°')
    parser.add_argument('--model-path', type=str, default=None,
                       help='è‡ªå®šä¹‰æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆä½¿ç”¨è¯¥è·¯å¾„ï¼‰')
    parser.add_argument('--conf', type=float, default=0.3, 
                       help='ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--device', type=str, default='auto', 
                       help='è¿è¡Œè®¾å¤‡ (auto/cuda/cpu)')
    parser.add_argument('--models-dir', type=str, default='models',
                       help='æ¨¡å‹å­˜æ”¾ç›®å½•')
    parser.add_argument('--save-faces', action='store_true', default=False,
                       help='ä¿å­˜è£å‰ªçš„äººè„¸åˆ°dataç›®å½•')
    parser.add_argument('--no-save-faces', dest='save_faces', action='store_false',
                       help='ä¸ä¿å­˜è£å‰ªçš„äººè„¸')
    parser.add_argument('--save-interval-sec', type=float, default=5.0,
                       help='ä¿å­˜äººè„¸çš„æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤5ç§’')
    
    # InsightFace äººè„¸åŒ¹é…å‚æ•°
    parser.add_argument('--photo-folder', type=str, default=None,
                       help='äººè„¸ç…§ç‰‡åº“æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆç”¨äºäººè„¸è¯†åˆ«åŒ¹é…ï¼‰')
    parser.add_argument('--similarity-threshold', type=float, default=DEFAULT_SIMILARITY_THRESHOLD,
                       help=f'ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼ä¸ºæœªçŸ¥äººå‘˜ï¼Œé»˜è®¤{DEFAULT_SIMILARITY_THRESHOLD}')
    parser.add_argument('--insightface-model', type=str, default='buffalo_sc',
                       help='InsightFaceæ¨¡å‹åç§°: buffalo_l(æ¨è) æˆ– buffalo_s(æ›´å¿«) æˆ– buffalo_sc(æœ€å¿«)')
    parser.add_argument('--no-recognition', action='store_true',
                       help='ç¦ç”¨äººè„¸è¯†åˆ«åŠŸèƒ½')
    
    # è·Ÿè¸ªç›¸å…³å‚æ•°
    parser.add_argument('--track', action='store_true', default=False,
                       help='å¯ç”¨è·Ÿè¸ªåŠŸèƒ½ (ByteTrack/BotSORT)')
    parser.add_argument('--no-track', dest='track', action='store_false',
                       help='ç¦ç”¨è·Ÿè¸ªåŠŸèƒ½')
    parser.add_argument('--tracker', type=str, default='bytetrack',
                       choices=['bytetrack', 'botsort'],
                       help='è·Ÿè¸ªå™¨ç±»å‹: bytetrack(å¿«é€Ÿ) æˆ– botsort(æ›´ç²¾ç¡®)')
    parser.add_argument('--track-buffer', type=int, default=30,
                       help='è·Ÿè¸ªç¼“å†²å¸§æ•°(è½¨è¿¹æœ€å¤§ä¸¢å¤±å¸§æ•°ï¼‰ï¼Œé»˜è®¤30')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–ä¸“ä¸šäººè„¸æ£€æµ‹å™¨
        print(f"ğŸš€ åˆå§‹åŒ–YOLOv8äººè„¸æ£€æµ‹å™¨...")
        detector = YOLOSpecializedFaceDetector(
            model_name=args.model,
            conf_threshold=args.conf,
            device=args.device,
            models_dir=args.models_dir,
            model_path=args.model_path,
            photo_folder=args.photo_folder,
            similarity_threshold=args.similarity_threshold,
            insightface_model_name=args.insightface_model,
            enable_tracking=args.track,
            tracker_type=args.tracker,
            track_buffer=args.track_buffer
        )
        
        enable_recognition = not args.no_recognition and detector.face_matcher is not None
        enable_tracking = args.track
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        input_path = Path(args.input)
        if not input_path.exists():
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
            return
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        output_path = args.output
        if not output_path:
            output_path = input_path.parent / f"yolov8_detected_{input_path.name}"
        
        # å¤„ç†è§†é¢‘æ–‡ä»¶
        if input_path.is_file() and input_path.suffix.lower() in ['.mp4', '.avi', '.mov', '.mkv']:
            # åˆ›å»ºä¸“ç”¨çš„è§†é¢‘å¤„ç†æ–¹æ³•
            process_video_with_yolov8(
                detector=detector,
                video_path=input_path,
                output_path=output_path,
                show_video=args.show,
                max_frames=args.max_frames,
                start_time=args.start_time,
                end_time=args.end_time,
                save_faces=args.save_faces,
                save_interval_sec=args.save_interval_sec,
                enable_recognition=enable_recognition,
                enable_tracking=enable_tracking
            )
        
        # å¤„ç†å›¾ç‰‡æ–‡ä»¶
        elif input_path.is_file() and input_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
            image = cv2.imread(str(input_path))
            faces, vis_image = detector.detect_faces(image, visualize=True, recognize=enable_recognition)
            
            # ä¿å­˜è£å‰ªçš„äººè„¸
            if args.save_faces and len(faces) > 0:
                data_dir = input_path.parent / 'data'
                data_dir.mkdir(parents=True, exist_ok=True)
                print(f"ğŸ“ äººè„¸å°†ä¿å­˜åˆ°: {data_dir}")
                
                for face_idx, face in enumerate(faces):
                    x1, y1, x2, y2 = face['bbox']
                    confidence = face['confidence']
                    
                    # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
                    x1 = max(0, int(x1))
                    y1 = max(0, int(y1))
                    x2 = min(image.shape[1], int(x2))
                    y2 = min(image.shape[0], int(y2))
                    
                    # è£å‰ªäººè„¸åŒºåŸŸ
                    face_crop = image[y1:y2, x1:x2]
                    
                    # åªä¿å­˜æœ‰æ•ˆçš„äººè„¸ï¼ˆå°ºå¯¸ä¸èƒ½å¤ªå°ï¼‰
                    if face_crop.shape[0] > 20 and face_crop.shape[1] > 20:
                        face_filename = f"{input_path.stem}_face_{face_idx:02d}_conf_{confidence:.3f}.jpg"
                        face_path = data_dir / face_filename
                        cv2.imwrite(str(face_path), face_crop)
                        print(f"   ğŸ’¾ ä¿å­˜äººè„¸: {face_filename}")
            
            # ä¿å­˜ç»“æœ
            if not output_path:
                output_path = input_path.parent / f"yolov8_detected_{input_path.name}"
            
            cv2.imwrite(str(output_path), vis_image)
            
            print(f"âœ… æ£€æµ‹åˆ° {len(faces)} ä¸ªäººè„¸")
            recognized_count = 0
            for i, face in enumerate(faces):
                bbox = face['bbox']
                conf = face['confidence']
                name = face.get('name', 'æœªçŸ¥äººå‘˜')
                if name != 'æœªçŸ¥äººå‘˜':
                    recognized_count += 1
                    print(f"   äººè„¸{i+1}: {name}, åæ ‡{bbox}, ç½®ä¿¡åº¦{conf:.3f}")
                else:
                    print(f"   äººè„¸{i+1}: æœªçŸ¥äººå‘˜, åæ ‡{bbox}, ç½®ä¿¡åº¦{conf:.3f}")
            
            if enable_recognition:
                print(f"ğŸ“Š è¯†åˆ«ç»“æœ: {recognized_count}/{len(faces)} äººè¢«è¯†åˆ«")
            
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            
            # æ˜¾ç¤ºç»“æœ
            if args.show:
                cv2.imshow('YOLOv8ä¸“ä¸šäººè„¸æ£€æµ‹', vis_image)
                cv2.waitKey(0)
                cv2.destroyAllWindows()
        
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {input_path}")
    
    except Exception as e:
        print(f"âŒ æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("ğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("   2. ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸ï¼ˆç”¨äºä¸‹è½½æ¨¡å‹ï¼‰")
        print("   3. æ£€æŸ¥è®¾å¤‡å’ŒCUDAç¯å¢ƒ")


if __name__ == '__main__':
    main()
