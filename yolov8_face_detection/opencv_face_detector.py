#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OpenCV ä¸“ä¸šäººè„¸æ£€æµ‹å™¨
ä½¿ç”¨ Haar Cascade åˆ†ç±»å™¨è¿›è¡Œé«˜ç²¾åº¦äººè„¸æ£€æµ‹
"""

import cv2
import numpy as np
import argparse
from pathlib import Path
import time


class OpenCVFaceDetector:
    """OpenCV äººè„¸æ£€æµ‹å™¨ç±»"""
    
    def __init__(self, scale_factor=1.1, min_neighbors=5, min_size=(30, 30)):
        """
        åˆå§‹åŒ– OpenCV äººè„¸æ£€æµ‹å™¨
        
        Args:
            scale_factor (float): å›¾åƒç¼©æ”¾å› å­
            min_neighbors (int): æœ€å°‘é‚»å±…æ•°é‡
            min_size (tuple): æœ€å°äººè„¸å°ºå¯¸
        """
        self.scale_factor = scale_factor
        self.min_neighbors = min_neighbors
        self.min_size = min_size
        
        # åŠ è½½äººè„¸æ£€æµ‹å™¨
        try:
            # æ­£é¢äººè„¸æ£€æµ‹å™¨
            self.face_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            )
            
            # ä¾§é¢äººè„¸æ£€æµ‹å™¨ (å¤‡ç”¨)
            self.profile_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_profileface.xml'
            )
            
            print("âœ… OpenCV äººè„¸æ£€æµ‹å™¨åŠ è½½æˆåŠŸ")
            print(f"ğŸ”§ å‚æ•°: scale_factor={scale_factor}, min_neighbors={min_neighbors}, min_size={min_size}")
            
        except Exception as e:
            print(f"âŒ äººè„¸æ£€æµ‹å™¨åŠ è½½å¤±è´¥: {e}")
            raise
    
    def detect_faces(self, image, detect_profile=True):
        """
        æ£€æµ‹å›¾åƒä¸­çš„äººè„¸
        
        Args:
            image: è¾“å…¥å›¾åƒ
            detect_profile (bool): æ˜¯å¦æ£€æµ‹ä¾§é¢äººè„¸
            
        Returns:
            list: æ£€æµ‹åˆ°çš„äººè„¸è¾¹ç•Œæ¡†åˆ—è¡¨ [(x, y, w, h), ...]
        """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image
        
        # ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼Œå¢å¼ºå¯¹æ¯”åº¦
        gray = cv2.equalizeHist(gray)
        
        # æ£€æµ‹æ­£é¢äººè„¸
        faces = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=self.scale_factor,
            minNeighbors=self.min_neighbors,
            minSize=self.min_size,
            flags=cv2.CASCADE_SCALE_IMAGE
        )
        
        # æ£€æµ‹ä¾§é¢äººè„¸ (å¯é€‰)
        if detect_profile:
            profile_faces = self.profile_cascade.detectMultiScale(
                gray,
                scaleFactor=self.scale_factor,
                minNeighbors=self.min_neighbors,
                minSize=self.min_size,
                flags=cv2.CASCADE_SCALE_IMAGE
            )
            
            # åˆå¹¶æ£€æµ‹ç»“æœ
            if len(profile_faces) > 0:
                if len(faces) > 0:
                    faces = np.vstack((faces, profile_faces))
                else:
                    faces = profile_faces
        
        return faces
    
    def _parse_time(self, time_input):
        """
        è§£ææ—¶é—´è¾“å…¥ï¼Œæ”¯æŒç§’æ•°æˆ– HH:MM:SS æ ¼å¼
        
        Args:
            time_input: æ—¶é—´è¾“å…¥ (float, int, æˆ– "HH:MM:SS" å­—ç¬¦ä¸²)
            
        Returns:
            float: æ—¶é—´ï¼ˆç§’ï¼‰
        """
        if time_input is None:
            return None
            
        if isinstance(time_input, (int, float)):
            return float(time_input)
            
        if isinstance(time_input, str):
            # è§£æ HH:MM:SS æˆ– MM:SS æ ¼å¼
            parts = time_input.split(':')
            if len(parts) == 3:  # HH:MM:SS
                hours, minutes, seconds = map(float, parts)
                return hours * 3600 + minutes * 60 + seconds
            elif len(parts) == 2:  # MM:SS
                minutes, seconds = map(float, parts)
                return minutes * 60 + seconds
            else:  # åªæœ‰ç§’æ•°
                return float(parts[0])
        
        return None
    
    def process_video(self, video_path, output_path=None, show_video=False, max_frames=None, 
                     start_time=None, end_time=None):
        """
        å¤„ç†è§†é¢‘æ–‡ä»¶è¿›è¡Œäººè„¸æ£€æµ‹
        
        Args:
            video_path (str): è¾“å…¥è§†é¢‘è·¯å¾„
            output_path (str): è¾“å‡ºè§†é¢‘è·¯å¾„
            show_video (bool): æ˜¯å¦æ˜¾ç¤ºè§†é¢‘çª—å£
            max_frames (int): æœ€å¤§å¤„ç†å¸§æ•° (Noneè¡¨ç¤ºå¤„ç†å…¨éƒ¨)
            start_time (float): å¼€å§‹æ—¶é—´(ç§’) æˆ– æ—¶é—´å­—ç¬¦ä¸² "HH:MM:SS"
            end_time (float): ç»“æŸæ—¶é—´(ç§’) æˆ– æ—¶é—´å­—ç¬¦ä¸² "HH:MM:SS"
        """
        print(f"ğŸ¥ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
        
        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
            return
        
        # è·å–è§†é¢‘å±æ€§
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        
        print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}FPS, æ€»å¸§æ•°={total_frames}, æ—¶é•¿={duration:.1f}ç§’")
        
        # è§£æå¼€å§‹å’Œç»“æŸæ—¶é—´
        start_seconds = self._parse_time(start_time)
        end_seconds = self._parse_time(end_time)
        
        # è®¡ç®—å¼€å§‹å’Œç»“æŸå¸§
        start_frame = 0
        end_frame = total_frames
        
        if start_seconds is not None:
            start_frame = int(start_seconds * fps)
            start_frame = max(0, min(start_frame, total_frames - 1))
            print(f"â© è·³è½¬åˆ°å¼€å§‹æ—¶é—´: {start_seconds:.1f}ç§’ (ç¬¬{start_frame}å¸§)")
            
        if end_seconds is not None:
            end_frame = int(end_seconds * fps)
            end_frame = max(start_frame, min(end_frame, total_frames))
            print(f"â¹ï¸  ç»“æŸæ—¶é—´: {end_seconds:.1f}ç§’ (ç¬¬{end_frame}å¸§)")
        
        # è·³è½¬åˆ°å¼€å§‹ä½ç½®
        if start_frame > 0:
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            actual_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)
            actual_time = actual_pos / fps if fps > 0 else 0
            print(f"âœ… å®é™…è·³è½¬åˆ°: ç¬¬{actual_pos:.0f}å¸§, {actual_time:.1f}ç§’")
        
        # è®¡ç®—å®é™…å¤„ç†çš„å¸§æ•°èŒƒå›´
        process_frames = end_frame - start_frame
        if max_frames:
            process_frames = min(process_frames, max_frames)
            
        print(f"ğŸ¯ å°†å¤„ç† {process_frames} å¸§ (ä»ç¬¬{start_frame}å¸§åˆ°ç¬¬{start_frame + process_frames}å¸§)")
        
        # è®¾ç½®è§†é¢‘å†™å…¥å™¨
        writer = None
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            writer = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
            print(f"ğŸ“ è¾“å‡ºè§†é¢‘: {output_path}")
        
        # å¤„ç†ç»Ÿè®¡
        frame_count = 0
        processed_frames = 0
        total_faces = 0
        process_start_time = time.time()
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # è·å–å½“å‰å¸§ä½ç½®
                current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
                current_time_sec = current_frame / fps if fps > 0 else 0
                
                # æ£€æŸ¥æ˜¯å¦è¶…å‡ºç»“æŸæ—¶é—´
                if end_seconds is not None and current_time_sec > end_seconds:
                    print(f"â¹ï¸  å·²è¾¾åˆ°ç»“æŸæ—¶é—´: {end_seconds:.1f}ç§’")
                    break
                
                # æ£€æŸ¥æœ€å¤§å¸§æ•°é™åˆ¶
                if max_frames and processed_frames >= max_frames:
                    print(f"â¹ï¸  å·²è¾¾åˆ°æœ€å¤§å¤„ç†å¸§æ•°: {max_frames}")
                    break
                
                # æ£€æŸ¥æ˜¯å¦è¶…å‡ºè®¡åˆ’å¤„ç†çš„å¸§æ•°
                if processed_frames >= process_frames:
                    print(f"â¹ï¸  å·²å®Œæˆè®¡åˆ’å¤„ç†çš„å¸§æ•°: {process_frames}")
                    break
                
                # æ£€æµ‹äººè„¸
                faces = self.detect_faces(frame, detect_profile=True)
                total_faces += len(faces)
                
                # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                result_frame = frame.copy()
                for (x, y, w, h) in faces:
                    # ç»˜åˆ¶äººè„¸æ¡†
                    cv2.rectangle(result_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                    
                    # æ·»åŠ ç½®ä¿¡åº¦æ ‡ç­¾
                    confidence = 0.95  # OpenCVæ£€æµ‹å™¨æ²¡æœ‰ç½®ä¿¡åº¦ï¼Œè®¾ç½®å›ºå®šå€¼
                    label = f'Face: {confidence:.2f}'
                    label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                    
                    # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                    cv2.rectangle(result_frame, (x, y - label_size[1] - 10), 
                                (x + label_size[0], y), (0, 255, 0), -1)
                    
                    # ç»˜åˆ¶æ ‡ç­¾æ–‡å­—
                    cv2.putText(result_frame, label, (x, y - 5), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
                
                # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
                elapsed_time = time.time() - process_start_time
                current_fps = processed_frames / elapsed_time if elapsed_time > 0 else 0
                
                # è®¡ç®—å½“å‰æ—¶é—´æˆ³
                hours = int(current_time_sec // 3600)
                minutes = int((current_time_sec % 3600) // 60)
                seconds = int(current_time_sec % 60)
                
                stats_text = [
                    f'Time: {hours:02d}:{minutes:02d}:{seconds:02d} (Frame: {current_frame})',
                    f'Progress: {processed_frames+1}/{process_frames}',
                    f'Current Faces: {len(faces)}',
                    f'Total Faces: {total_faces}',
                    f'Processing FPS: {current_fps:.1f}'
                ]
                
                for i, text in enumerate(stats_text):
                    y_pos = 30 + i * 25
                    cv2.putText(result_frame, text, (10, y_pos), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
                
                # ä¿å­˜å¸§
                if writer:
                    writer.write(result_frame)
                
                # æ˜¾ç¤ºè§†é¢‘
                if show_video:
                    cv2.imshow('äººè„¸æ£€æµ‹', result_frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        print("ğŸ‘¤ ç”¨æˆ·æŒ‰'q'é”®é€€å‡º")
                        break
                
                processed_frames += 1
                
                # å®šæœŸè¾“å‡ºè¿›åº¦
                if processed_frames % 100 == 0:
                    progress = (processed_frames / process_frames) * 100
                    current_time_str = f"{hours:02d}:{minutes:02d}:{seconds:02d}"
                    print(f"ğŸ“ˆ å¤„ç†è¿›åº¦: {processed_frames}/{process_frames} "
                          f"({progress:.1f}%) | æ—¶é—´: {current_time_str} | æ£€æµ‹åˆ°äººè„¸: {total_faces}")
        
        except KeyboardInterrupt:
            print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
        
        finally:
            # æ¸…ç†èµ„æº
            cap.release()
            if writer:
                writer.release()
            if show_video:
                cv2.destroyAllWindows()
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        elapsed_time = time.time() - process_start_time
        avg_fps = processed_frames / elapsed_time if elapsed_time > 0 else 0
        
        print(f"\nğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
        print(f"   â±ï¸  å¤„ç†æ—¶é—´: {elapsed_time:.1f}ç§’")
        print(f"   ğŸ“¹ å¤„ç†å¸§æ•°: {processed_frames}")
        print(f"   ğŸ¯ æ£€æµ‹äººè„¸: {total_faces}")
        print(f"   âš¡ å¹³å‡FPS: {avg_fps:.1f}")
        print(f"   ğŸ“ å¹³å‡æ¯å¸§äººè„¸æ•°: {total_faces/processed_frames:.1f}" if processed_frames > 0 else "")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='OpenCV ä¸“ä¸šäººè„¸æ£€æµ‹å™¨')
    parser.add_argument('--input', type=str, required=True,
                       help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, 
                       help='è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--show', action='store_true',
                       help='æ˜¾ç¤ºæ£€æµ‹è¿‡ç¨‹')
    parser.add_argument('--max-frames', type=int,
                       help='æœ€å¤§å¤„ç†å¸§æ•° (ç”¨äºæµ‹è¯•)')
    parser.add_argument('--scale-factor', type=float, default=1.1,
                       help='æ£€æµ‹ç¼©æ”¾å› å­')
    parser.add_argument('--min-neighbors', type=int, default=5,
                       help='æœ€å°é‚»å±…æ•°')
    parser.add_argument('--min-size', type=int, nargs=2, default=[30, 30],
                       help='æœ€å°äººè„¸å°ºå¯¸ [width height]')
    parser.add_argument('--start-time', type=str,
                       help='å¼€å§‹æ—¶é—´ (ç§’æ•°æˆ– HH:MM:SS æ ¼å¼)')
    parser.add_argument('--end-time', type=str, 
                       help='ç»“æŸæ—¶é—´ (ç§’æ•°æˆ– HH:MM:SS æ ¼å¼)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    # è®¾ç½®è¾“å‡ºè·¯å¾„
    output_path = args.output
    if not output_path:
        output_path = input_path.parent / f"opencv_detected_{input_path.name}"
    
    try:
        # åˆ›å»ºæ£€æµ‹å™¨
        detector = OpenCVFaceDetector(
            scale_factor=args.scale_factor,
            min_neighbors=args.min_neighbors,
            min_size=tuple(args.min_size)
        )
        
        # å¤„ç†è§†é¢‘
        detector.process_video(
            video_path=input_path,
            output_path=output_path,
            show_video=args.show,
            max_frames=args.max_frames,
            start_time=args.start_time,
            end_time=args.end_time
        )
        
        print(f"ğŸ‰ å¤„ç†å®Œæˆ! ç»“æœä¿å­˜åœ¨: {output_path}")
        
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


if __name__ == '__main__':
    main()
