#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸“é—¨çš„YOLOv8äººè„¸æ£€æµ‹å™¨
ä½¿ç”¨ä¸“ä¸šçš„yolov8-faceæ¨¡å‹è¿›è¡Œé«˜ç²¾åº¦äººè„¸æ£€æµ‹
"""

import cv2
import numpy as np
from pathlib import Path
import torch
from ultralytics import YOLO
import argparse
import time
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥å…¶ä»–è„šæœ¬
sys.path.append(str(Path(__file__).parent))

from face_detector import YOLOv8FaceDetector


def check_and_download_model(model_path, model_name='yolov8n-face'):
    """
    æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½
    
    Args:
        model_path (Path): æ¨¡å‹æ–‡ä»¶è·¯å¾„
        model_name (str): æ¨¡å‹åç§°
        
    Returns:
        bool: æ¨¡å‹æ˜¯å¦å¯ç”¨
    """
    if model_path.exists():
        print(f"âœ… æ‰¾åˆ°äººè„¸æ£€æµ‹æ¨¡å‹: {model_path}")
        return True
    
    print(f"âš ï¸  æœªæ‰¾åˆ°äººè„¸æ£€æµ‹æ¨¡å‹: {model_path}")
    print(f"ğŸ”„ å¼€å§‹è‡ªåŠ¨ä¸‹è½½ {model_name} æ¨¡å‹...")
    
    try:
        # å¯¼å…¥ä¸‹è½½è„šæœ¬
        from scripts.download_face_models import download_file
        
        # äººè„¸æ£€æµ‹æ¨¡å‹ä¸‹è½½é“¾æ¥
        face_model_urls = {
            'yolov8n-face': 'https://github.com/lindevs/yolov8-face/releases/latest/download/yolov8n-face-lindevs.pt',
            'yolov8s-face': 'https://huggingface.co/Bingsu/adetailer/resolve/main/face_yolov8s.pt',
        }
        
        if model_name not in face_model_urls:
            print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
            return False
        
        # åˆ›å»ºæ¨¡å‹ç›®å½•
        model_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¸‹è½½æ¨¡å‹
        download_file(face_model_urls[model_name], str(model_path))
        
        if model_path.exists() and model_path.stat().st_size > 1024 * 1024:
            print(f"âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ: {model_path}")
            return True
        else:
            print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥æˆ–æ–‡ä»¶æŸå")
            return False
            
    except Exception as e:
        print(f"âŒ è‡ªåŠ¨ä¸‹è½½å¤±è´¥: {e}")
        print(f"ğŸ’¡ è¯·æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹åˆ°: {model_path}")
        if model_name == 'yolov8n-face':
            print(f"   ä¸‹è½½é“¾æ¥: https://github.com/lindevs/yolov8-face/releases/latest/download/yolov8n-face-lindevs.pt")
        else:
            print(f"   ä¸‹è½½é“¾æ¥: https://huggingface.co/Bingsu/adetailer/tree/main")
        return False


class YOLOv8SpecializedFaceDetector(YOLOv8FaceDetector):
    """ä¸“é—¨çš„YOLOv8äººè„¸æ£€æµ‹å™¨ï¼Œä½¿ç”¨ä¼˜åŒ–çš„äººè„¸æ£€æµ‹æ¨¡å‹"""
    
    def __init__(self, model_name='yolov8n-face', conf_threshold=0.3, device='auto', 
                 models_dir='models'):
        """
        åˆå§‹åŒ–ä¸“é—¨çš„äººè„¸æ£€æµ‹å™¨
        
        Args:
            model_name (str): æ¨¡å‹åç§° ('yolov8n-face', 'yolov8s-face')
            conf_threshold (float): ç½®ä¿¡åº¦é˜ˆå€¼
            device (str): è¿è¡Œè®¾å¤‡
            models_dir (str): æ¨¡å‹ç›®å½•
        """
        self.model_name = model_name
        self.models_dir = Path(models_dir)
        
        # æ„é€ æ¨¡å‹è·¯å¾„
        model_path = self.models_dir / f"{model_name}.pt"
        
        # æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡å‹
        if not check_and_download_model(model_path, model_name):
            raise RuntimeError(f"æ— æ³•è·å–äººè„¸æ£€æµ‹æ¨¡å‹: {model_name}")
        
        # ä½¿ç”¨çˆ¶ç±»åˆå§‹åŒ–
        super().__init__(
            model_path=str(model_path),
            conf_threshold=conf_threshold,
            device=device
        )
        
        print(f"ğŸ¯ ä¸“ä¸šäººè„¸æ£€æµ‹å™¨å·²å°±ç»ª")
        print(f"ğŸ“¦ æ¨¡å‹: {model_name}")
        print(f"ğŸšï¸  ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
    
    def detect_faces(self, image, visualize=True):
        """
        æ£€æµ‹å›¾ç‰‡ä¸­çš„äººè„¸ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        
        Args:
            image: è¾“å…¥å›¾åƒ
            visualize (bool): æ˜¯å¦å¯è§†åŒ–æ£€æµ‹ç»“æœ
            
        Returns:
            tuple: (æ£€æµ‹ç»“æœ, å¯è§†åŒ–å›¾åƒ)
        """
        # è¿è¡Œæ¨ç†
        results = self.model(image, conf=self.conf_threshold, verbose=False)
        
        faces = []
        vis_image = image.copy() if isinstance(image, np.ndarray) else np.array(image)
        
        # è§£ææ£€æµ‹ç»“æœ
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    confidence = box.conf[0].cpu().numpy()
                    
                    face_info = {
                        'bbox': [int(x1), int(y1), int(x2), int(y2)],
                        'confidence': float(confidence)
                    }
                    faces.append(face_info)
                    
                    if visualize:
                        # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆä½¿ç”¨æ›´æ˜¾çœ¼çš„é¢œè‰²ï¼‰
                        cv2.rectangle(vis_image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 255), 2)
                        
                        # æ·»åŠ ç½®ä¿¡åº¦æ ‡ç­¾
                        label = f'Face: {confidence:.3f}'
                        label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                        cv2.rectangle(vis_image, (int(x1), int(y1) - label_size[1] - 10), 
                                    (int(x1) + label_size[0], int(y1)), (0, 255, 255), -1)
                        cv2.putText(vis_image, label, (int(x1), int(y1) - 5), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)
        
        return faces, vis_image


def process_video_with_yolov8(detector, video_path, output_path=None, show_video=False, 
                              max_frames=None, start_time=None, end_time=None):
    """
    ä½¿ç”¨YOLOv8å¤„ç†è§†é¢‘æ–‡ä»¶è¿›è¡Œäººè„¸æ£€æµ‹
    """
    print(f"ğŸ¥ å¼€å§‹å¤„ç†è§†é¢‘: {video_path}")
    
    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
        return
    
    # è·å–è§†é¢‘å±æ€§
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps if fps > 0 else 0
    
    print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}FPS, æ€»å¸§æ•°={total_frames}, æ—¶é•¿={duration:.1f}ç§’")
    
    # è§£ææ—¶é—´å‚æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä¸opencv_face_detectorä¿æŒä¸€è‡´ï¼‰
    start_frame = 0
    end_frame = total_frames
    
    if start_time:
        try:
            if ':' in start_time:
                parts = start_time.split(':')
                if len(parts) == 3:  # HH:MM:SS
                    hours, minutes, seconds = map(float, parts)
                    start_seconds = hours * 3600 + minutes * 60 + seconds
                elif len(parts) == 2:  # MM:SS
                    minutes, seconds = map(float, parts)
                    start_seconds = minutes * 60 + seconds
            else:
                start_seconds = float(start_time)
            
            start_frame = int(start_seconds * fps)
            start_frame = max(0, min(start_frame, total_frames - 1))
            cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
            print(f"â© è·³è½¬åˆ°å¼€å§‹æ—¶é—´: {start_seconds:.1f}ç§’ (ç¬¬{start_frame}å¸§)")
        except:
            print(f"âš ï¸  æ— æ•ˆçš„å¼€å§‹æ—¶é—´æ ¼å¼: {start_time}")
    
    if end_time:
        try:
            if ':' in end_time:
                parts = end_time.split(':')
                if len(parts) == 3:  # HH:MM:SS
                    hours, minutes, seconds = map(float, parts)
                    end_seconds = hours * 3600 + minutes * 60 + seconds
                elif len(parts) == 2:  # MM:SS
                    minutes, seconds = map(float, parts)
                    end_seconds = minutes * 60 + seconds
            else:
                end_seconds = float(end_time)
                
            end_frame = int(end_seconds * fps)
            end_frame = max(start_frame, min(end_frame, total_frames))
            print(f"â¹ï¸  ç»“æŸæ—¶é—´: {end_seconds:.1f}ç§’ (ç¬¬{end_frame}å¸§)")
        except:
            print(f"âš ï¸  æ— æ•ˆçš„ç»“æŸæ—¶é—´æ ¼å¼: {end_time}")
    
    # è®¡ç®—å¤„ç†å¸§æ•°
    process_frames = end_frame - start_frame
    if max_frames:
        process_frames = min(process_frames, max_frames)
    
    # è®¾ç½®è§†é¢‘å†™å…¥å™¨
    writer = None
    if output_path:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        writer = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
        print(f"ğŸ“ è¾“å‡ºè§†é¢‘: {output_path}")
    
    # å¤„ç†ç»Ÿè®¡
    processed_frames = 0
    total_faces = 0
    process_start_time = time.time()
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # è·å–å½“å‰å¸§ä½ç½®
            current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
            current_time_sec = current_frame / fps if fps > 0 else 0
            
            # æ£€æŸ¥å¤„ç†é™åˆ¶
            if processed_frames >= process_frames:
                break
                
            if max_frames and processed_frames >= max_frames:
                print(f"â¹ï¸  å·²è¾¾åˆ°æœ€å¤§å¤„ç†å¸§æ•°: {max_frames}")
                break
            
            # æ£€æµ‹äººè„¸
            faces, vis_frame = detector.detect_faces(frame, visualize=True)
            total_faces += len(faces)
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            elapsed_time = time.time() - process_start_time
            current_fps = processed_frames / elapsed_time if elapsed_time > 0 else 0
            
            hours = int(current_time_sec // 3600)
            minutes = int((current_time_sec % 3600) // 60)
            seconds = int(current_time_sec % 60)
            
            stats_text = [
                f'Time: {hours:02d}:{minutes:02d}:{seconds:02d} (Frame: {current_frame})',
                f'Progress: {processed_frames+1}/{process_frames}',
                f'Current Faces: {len(faces)}',
                f'Total Faces: {total_faces}',
                f'Processing FPS: {current_fps:.1f}'
            ]
            
            for i, text in enumerate(stats_text):
                y_pos = 30 + i * 25
                cv2.putText(vis_frame, text, (10, y_pos), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            
            # ä¿å­˜å¸§
            if writer:
                writer.write(vis_frame)
            
            # æ˜¾ç¤ºè§†é¢‘
            if show_video:
                cv2.imshow('YOLOv8äººè„¸æ£€æµ‹', vis_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("ğŸ‘¤ ç”¨æˆ·æŒ‰'q'é”®é€€å‡º")
                    break
            
            processed_frames += 1
            
            # å®šæœŸè¾“å‡ºè¿›åº¦
            if processed_frames % 100 == 0:
                progress = (processed_frames / process_frames) * 100
                current_time_str = f"{hours:02d}:{minutes:02d}:{seconds:02d}"
                print(f"ğŸ“ˆ å¤„ç†è¿›åº¦: {processed_frames}/{process_frames} "
                      f"({progress:.1f}%) | æ—¶é—´: {current_time_str} | æ£€æµ‹åˆ°äººè„¸: {total_faces}")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­å¤„ç†")
    
    finally:
        # æ¸…ç†èµ„æº
        cap.release()
        if writer:
            writer.release()
        if show_video:
            cv2.destroyAllWindows()
    
    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    elapsed_time = time.time() - process_start_time
    avg_fps = processed_frames / elapsed_time if elapsed_time > 0 else 0
    
    print(f"\nğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡:")
    print(f"   â±ï¸  å¤„ç†æ—¶é—´: {elapsed_time:.1f}ç§’")
    print(f"   ğŸ“¹ å¤„ç†å¸§æ•°: {processed_frames}")
    print(f"   ğŸ¯ æ£€æµ‹äººè„¸: {total_faces}")
    print(f"   âš¡ å¹³å‡FPS: {avg_fps:.1f}")
    print(f"   ğŸ“ å¹³å‡æ¯å¸§äººè„¸æ•°: {total_faces/processed_frames:.1f}" if processed_frames > 0 else "")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='YOLOv8ä¸“ä¸šäººè„¸æ£€æµ‹å™¨')
    parser.add_argument('--input', type=str, required=True,
                       help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, 
                       help='è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--show', action='store_true',
                       help='æ˜¾ç¤ºæ£€æµ‹è¿‡ç¨‹')
    parser.add_argument('--max-frames', type=int,
                       help='æœ€å¤§å¤„ç†å¸§æ•° (ç”¨äºæµ‹è¯•)')
    parser.add_argument('--start-time', type=str,
                       help='å¼€å§‹æ—¶é—´ (ç§’æ•°æˆ– HH:MM:SS æ ¼å¼)')
    parser.add_argument('--end-time', type=str, 
                       help='ç»“æŸæ—¶é—´ (ç§’æ•°æˆ– HH:MM:SS æ ¼å¼)')
    parser.add_argument('--model', type=str, default='yolov8n-face',
                       choices=['yolov8n-face', 'yolov8s-face'],
                       help='äººè„¸æ£€æµ‹æ¨¡å‹åç§°')
    parser.add_argument('--conf', type=float, default=0.3, 
                       help='ç½®ä¿¡åº¦é˜ˆå€¼')
    parser.add_argument('--device', type=str, default='auto', 
                       help='è¿è¡Œè®¾å¤‡')
    parser.add_argument('--models-dir', type=str, default='models',
                       help='æ¨¡å‹å­˜æ”¾ç›®å½•')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–ä¸“ä¸šäººè„¸æ£€æµ‹å™¨
        print(f"ğŸš€ åˆå§‹åŒ–YOLOv8ä¸“ä¸šäººè„¸æ£€æµ‹å™¨...")
        detector = YOLOv8SpecializedFaceDetector(
            model_name=args.model,
            conf_threshold=args.conf,
            device=args.device,
            models_dir=args.models_dir
        )
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        input_path = Path(args.input)
        if not input_path.exists():
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
            return
        
        # è®¾ç½®è¾“å‡ºè·¯å¾„
        output_path = args.output
        if not output_path:
            output_path = input_path.parent / f"yolov8_detected_{input_path.name}"
        
        # å¤„ç†è§†é¢‘æ–‡ä»¶
        if input_path.is_file() and input_path.suffix.lower() in ['.mp4', '.avi', '.mov', '.mkv']:
            # åˆ›å»ºä¸“ç”¨çš„è§†é¢‘å¤„ç†æ–¹æ³•
            process_video_with_yolov8(
                detector=detector,
                video_path=input_path,
                output_path=output_path,
                show_video=args.show,
                max_frames=args.max_frames,
                start_time=args.start_time,
                end_time=args.end_time
            )
        
        # å¤„ç†å›¾ç‰‡æ–‡ä»¶
        elif input_path.is_file() and input_path.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
            image = cv2.imread(str(input_path))
            faces, vis_image = detector.detect_faces(image, visualize=True)
            
            # ä¿å­˜ç»“æœ
            if not output_path:
                output_path = input_path.parent / f"yolov8_detected_{input_path.name}"
            
            cv2.imwrite(str(output_path), vis_image)
            
            print(f"âœ… æ£€æµ‹åˆ° {len(faces)} ä¸ªäººè„¸")
            for i, face in enumerate(faces):
                bbox = face['bbox']
                conf = face['confidence']
                print(f"   äººè„¸{i+1}: åæ ‡{bbox}, ç½®ä¿¡åº¦{conf:.3f}")
            
            print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            
            # æ˜¾ç¤ºç»“æœ
            if args.show:
                cv2.imshow('YOLOv8ä¸“ä¸šäººè„¸æ£€æµ‹', vis_image)
                cv2.waitKey(0)
                cv2.destroyAllWindows()
        
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {input_path}")
    
    except Exception as e:
        print(f"âŒ æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("ğŸ’¡ å»ºè®®:")
        print("   1. æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("   2. ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸ï¼ˆç”¨äºä¸‹è½½æ¨¡å‹ï¼‰")
        print("   3. æ£€æŸ¥è®¾å¤‡å’ŒCUDAç¯å¢ƒ")


if __name__ == '__main__':
    main()
