#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäº InsightFace çš„äººè„¸è¯†åˆ«ç³»ç»Ÿ

åŠŸèƒ½:
1) å¤šç±»åˆ«è®­ç»ƒï¼šç›®å½•ä¸‹çš„å­ç›®å½•æ˜¯æ ‡ç­¾ï¼Œå­ç›®å½•ä¸‹çš„å›¾ç‰‡æ˜¯æ•°æ®
2) å•å›¾åŒ¹é…ï¼šè¾“å…¥ä¸€å¼ å›¾ç‰‡ï¼Œæ‰¾å‡ºæœ€åƒå“ªä¸ªäºº
3) æ‰¹é‡åˆ†ç±»ï¼šæ‰¹é‡å¤„ç†å¤šå¼ å›¾ç‰‡

å®‰è£…ä¾èµ–:
    pip install insightface onnxruntime-gpu  # GPUç‰ˆæœ¬
    # æˆ–
    pip install insightface onnxruntime      # CPUç‰ˆæœ¬
"""

import os
import glob
import numpy as np
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
from PIL import Image
import cv2

try:
    from tqdm import tqdm
except ImportError:
    def tqdm(iterable, desc=""):
        print(f"{desc}...")
        return iterable

try:
    import insightface
    from insightface.app import FaceAnalysis
    INSIGHTFACE_AVAILABLE = True
except ImportError:
    INSIGHTFACE_AVAILABLE = False
    print("è­¦å‘Š: insightface æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install insightface onnxruntime")


@dataclass
class RecognitionResult:
    """è¯†åˆ«ç»“æœ"""
    name: str
    similarity: float
    all_similarities: Optional[Dict[str, float]] = None


class InsightFaceRecognizer:
    """åŸºäº InsightFace çš„äººè„¸è¯†åˆ«å™¨"""
    
    def __init__(self, model_name: str = 'buffalo_l', ctx_id: int = 0):
        """
        åˆå§‹åŒ– InsightFace æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œå¯é€‰ï¼š
                - 'buffalo_l' (æ¨èï¼Œç²¾åº¦é«˜)
                - 'buffalo_s' (æ›´å¿«ï¼Œç²¾åº¦ç•¥ä½)
                - 'buffalo_sc' (æœ€å¿«ï¼Œé€‚åˆè¾¹ç¼˜è®¾å¤‡)
            ctx_id: GPU IDï¼Œ-1 è¡¨ç¤ºä½¿ç”¨ CPU
        """
        if not INSIGHTFACE_AVAILABLE:
            raise RuntimeError("insightface æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install insightface onnxruntime")
        
        print(f"æ­£åœ¨åŠ è½½ InsightFace æ¨¡å‹: {model_name}...")
        print(f"ä½¿ç”¨è®¾å¤‡: {'GPU ' + str(ctx_id) if ctx_id >= 0 else 'CPU'}")
        
        # åˆå§‹åŒ–äººè„¸åˆ†æå™¨
        self.app = FaceAnalysis(
            name=model_name,
            providers=['CUDAExecutionProvider', 'CPUExecutionProvider'] if ctx_id >= 0 
                      else ['CPUExecutionProvider']
        )
        self.app.prepare(ctx_id=ctx_id, det_size=(640, 640))
        
        # å­˜å‚¨è®­ç»ƒæ•°æ®
        self.class_embeddings: Dict[str, np.ndarray] = {}  # {ç±»åˆ«å: å¹³å‡ç‰¹å¾å‘é‡}
        self.class_all_embeddings: Dict[str, List[np.ndarray]] = {}  # {ç±»åˆ«å: [æ‰€æœ‰ç‰¹å¾å‘é‡]}
        self.class_image_counts: Dict[str, int] = {}  # {ç±»åˆ«å: å›¾ç‰‡æ•°é‡}
        
        print("InsightFace æ¨¡å‹åŠ è½½å®Œæˆï¼")
    
    def extract_embedding(self, image_path: str) -> Optional[np.ndarray]:
        """
        ä»å›¾ç‰‡ä¸­æå–äººè„¸ç‰¹å¾å‘é‡
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
        
        Returns:
            np.ndarray: 512ç»´ç‰¹å¾å‘é‡ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°äººè„¸åˆ™è¿”å›None
        """
        # è¯»å–å›¾ç‰‡
        img = cv2.imread(image_path)
        if img is None:
            return None
        
        # æ£€æµ‹äººè„¸å¹¶æå–ç‰¹å¾
        faces = self.app.get(img)
        
        if len(faces) == 0:
            return None
        
        # å¦‚æœæœ‰å¤šä¸ªäººè„¸ï¼Œé€‰æ‹©æœ€å¤§çš„ï¼ˆé€šå¸¸æ˜¯æœ€è¿‘çš„ï¼‰
        if len(faces) > 1:
            faces = sorted(faces, key=lambda x: (x.bbox[2]-x.bbox[0])*(x.bbox[3]-x.bbox[1]), reverse=True)
        
        return faces[0].embedding
    
    def extract_embedding_from_array(self, img_bgr: np.ndarray) -> Optional[np.ndarray]:
        """
        ä» numpy æ•°ç»„å›¾ç‰‡ä¸­æå–äººè„¸ç‰¹å¾å‘é‡
        
        Args:
            img_bgr: BGRæ ¼å¼çš„å›¾ç‰‡æ•°ç»„
        
        Returns:
            np.ndarray: 512ç»´ç‰¹å¾å‘é‡
        """
        faces = self.app.get(img_bgr)
        
        if len(faces) == 0:
            return None
        
        if len(faces) > 1:
            faces = sorted(faces, key=lambda x: (x.bbox[2]-x.bbox[0])*(x.bbox[3]-x.bbox[1]), reverse=True)
        
        return faces[0].embedding
    
    def compute_similarity(self, emb1: np.ndarray, emb2: np.ndarray) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªç‰¹å¾å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦
        
        Args:
            emb1: ç‰¹å¾å‘é‡1
            emb2: ç‰¹å¾å‘é‡2
        
        Returns:
            float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        # å½’ä¸€åŒ–
        emb1 = emb1 / np.linalg.norm(emb1)
        emb2 = emb2 / np.linalg.norm(emb2)
        # ä½™å¼¦ç›¸ä¼¼åº¦
        sim = np.dot(emb1, emb2)
        # æ˜ å°„åˆ° 0-1 èŒƒå›´
        return (sim + 1) / 2
    
    def train_from_directory(self, train_dir: str, aggregation: str = 'mean', 
                             max_images_per_class: Optional[int] = None) -> Dict[str, int]:
        """
        å¤šç±»åˆ«è®­ç»ƒï¼šç›®å½•ä¸‹çš„å­ç›®å½•æ˜¯æ ‡ç­¾ï¼Œå­ç›®å½•ä¸‹çš„å›¾ç‰‡æ˜¯æ•°æ®
        
        ç›®å½•ç»“æ„ç¤ºä¾‹:
            train_dir/
            â”œâ”€â”€ å¼ ä¸‰/           <- å­ç›®å½•åæ˜¯æ ‡ç­¾
            â”‚   â”œâ”€â”€ photo1.jpg
            â”‚   â”œâ”€â”€ photo2.jpg
            â”‚   â””â”€â”€ ...
            â”œâ”€â”€ æå››/
            â”‚   â”œâ”€â”€ photo1.jpg
            â”‚   â””â”€â”€ ...
            â””â”€â”€ ç‹äº”/
                â””â”€â”€ ...
        
        Args:
            train_dir: è®­ç»ƒç›®å½•è·¯å¾„
            aggregation: ç‰¹å¾èšåˆæ–¹å¼ ('mean' æˆ– 'all')
                - 'mean': è®¡ç®—å¹³å‡ç‰¹å¾ï¼ˆæ¨èï¼Œé€Ÿåº¦å¿«ï¼‰
                - 'all': ä¿ç•™æ‰€æœ‰ç‰¹å¾ï¼ˆåŒ¹é…æ—¶å–æœ€é«˜ç›¸ä¼¼åº¦ï¼Œæ›´å‡†ç¡®ä½†æ›´æ…¢ï¼‰
            max_images_per_class: æ¯ä¸ªç±»åˆ«æœ€å¤šä½¿ç”¨çš„å›¾ç‰‡æ•°é‡
        
        Returns:
            dict: {ç±»åˆ«å: æˆåŠŸæå–çš„å›¾ç‰‡æ•°é‡}
        """
        if not os.path.exists(train_dir):
            raise FileNotFoundError(f"è®­ç»ƒç›®å½•ä¸å­˜åœ¨: {train_dir}")
        
        # è·å–æ‰€æœ‰å­ç›®å½•ä½œä¸ºç±»åˆ«
        subdirs = [d for d in os.listdir(train_dir) 
                   if os.path.isdir(os.path.join(train_dir, d))]
        
        if len(subdirs) == 0:
            raise ValueError(f"è®­ç»ƒç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°å­ç›®å½•ï¼ˆç±»åˆ«ï¼‰: {train_dir}")
        
        print(f"\næ‰¾åˆ° {len(subdirs)} ä¸ªç±»åˆ«")
        print("-" * 70)
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.JPG', '*.JPEG', '*.PNG']
        
        self.class_embeddings = {}
        self.class_all_embeddings = {}
        self.class_image_counts = {}
        
        for class_name in tqdm(subdirs, desc="è®­ç»ƒè¿›åº¦"):
            class_dir = os.path.join(train_dir, class_name)
            
            # è·å–è¯¥ç±»åˆ«ä¸‹çš„æ‰€æœ‰å›¾ç‰‡
            image_paths = []
            for ext in image_extensions:
                image_paths.extend(glob.glob(os.path.join(class_dir, ext)))
            
            image_paths = sorted(list(set(image_paths)))
            
            if len(image_paths) == 0:
                print(f"\nè­¦å‘Š: ç±»åˆ« '{class_name}' ä¸‹æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ï¼Œè·³è¿‡")
                continue
            
            # é™åˆ¶æ¯ä¸ªç±»åˆ«çš„å›¾ç‰‡æ•°é‡
            if max_images_per_class and len(image_paths) > max_images_per_class:
                image_paths = image_paths[:max_images_per_class]
            
            # æå–è¯¥ç±»åˆ«æ‰€æœ‰å›¾ç‰‡çš„ç‰¹å¾
            embeddings = []
            for img_path in image_paths:
                try:
                    emb = self.extract_embedding(img_path)
                    if emb is not None:
                        embeddings.append(emb)
                except Exception as e:
                    print(f"\nè­¦å‘Š: å¤„ç†å¤±è´¥ {img_path}: {str(e)}")
                    continue
            
            if len(embeddings) == 0:
                print(f"\nè­¦å‘Š: ç±»åˆ« '{class_name}' æ²¡æœ‰æˆåŠŸæå–ä»»ä½•äººè„¸ç‰¹å¾ï¼Œè·³è¿‡")
                continue
            
            # ä¿å­˜ç‰¹å¾
            self.class_all_embeddings[class_name] = embeddings
            self.class_image_counts[class_name] = len(embeddings)
            
            # èšåˆç‰¹å¾
            if aggregation == 'mean':
                avg_emb = np.mean(embeddings, axis=0)
                avg_emb = avg_emb / np.linalg.norm(avg_emb)  # å½’ä¸€åŒ–
                self.class_embeddings[class_name] = avg_emb
        
        # æ‰“å°è®­ç»ƒç»“æœ
        print("\n" + "=" * 70)
        print("è®­ç»ƒå®Œæˆï¼")
        print("=" * 70)
        print(f"æ€»ç±»åˆ«æ•°: {len(self.class_embeddings)}")
        total_images = 0
        for class_name, count in self.class_image_counts.items():
            print(f"  - {class_name}: {count} å¼ å›¾ç‰‡")
            total_images += count
        print(f"æ€»å›¾ç‰‡æ•°: {total_images}")
        
        return self.class_image_counts
    
    def classify_image(self, test_image_path: str, top_k: int = 5, 
                       use_all_embeddings: bool = False) -> List[Tuple[str, float]]:
        """
        å¯¹æµ‹è¯•å›¾ç‰‡è¿›è¡Œåˆ†ç±»ï¼Œæ‰¾å‡ºæœ€åƒå“ªä¸ªäºº
        
        Args:
            test_image_path: æµ‹è¯•å›¾ç‰‡è·¯å¾„
            top_k: è¿”å›å‰kä¸ªæœ€ç›¸ä¼¼çš„ç±»åˆ«
            use_all_embeddings: æ˜¯å¦ä½¿ç”¨æ‰€æœ‰ç‰¹å¾è¿›è¡ŒåŒ¹é…ï¼ˆæ›´å‡†ç¡®ä½†æ›´æ…¢ï¼‰
        
        Returns:
            list: [(ç±»åˆ«å, ç›¸ä¼¼åº¦), ...] æŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—
        """
        if len(self.class_embeddings) == 0 and len(self.class_all_embeddings) == 0:
            raise ValueError("è¯·å…ˆè°ƒç”¨ train_from_directory è¿›è¡Œè®­ç»ƒï¼")
        
        if not os.path.exists(test_image_path):
            raise FileNotFoundError(f"æµ‹è¯•å›¾ç‰‡ä¸å­˜åœ¨: {test_image_path}")
        
        # æå–æµ‹è¯•å›¾ç‰‡ç‰¹å¾
        test_emb = self.extract_embedding(test_image_path)
        
        if test_emb is None:
            print(f"è­¦å‘Š: æœªåœ¨æµ‹è¯•å›¾ç‰‡ä¸­æ£€æµ‹åˆ°äººè„¸: {test_image_path}")
            return []
        
        # è®¡ç®—ä¸æ‰€æœ‰ç±»åˆ«çš„ç›¸ä¼¼åº¦
        results = []
        
        if use_all_embeddings and self.class_all_embeddings:
            # ä½¿ç”¨æ‰€æœ‰ç‰¹å¾ï¼Œå–æœ€é«˜ç›¸ä¼¼åº¦
            for class_name, embeddings in self.class_all_embeddings.items():
                max_sim = max(self.compute_similarity(test_emb, emb) for emb in embeddings)
                results.append((class_name, max_sim))
        else:
            # ä½¿ç”¨å¹³å‡ç‰¹å¾
            for class_name, class_emb in self.class_embeddings.items():
                sim = self.compute_similarity(test_emb, class_emb)
                results.append((class_name, sim))
        
        # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        results.sort(key=lambda x: x[1], reverse=True)
        
        return results[:top_k]
    
    def classify_image_from_array(self, img_bgr: np.ndarray, top_k: int = 5,
                                  use_all_embeddings: bool = False) -> List[Tuple[str, float]]:
        """
        å¯¹ numpy æ•°ç»„å›¾ç‰‡è¿›è¡Œåˆ†ç±»
        
        Args:
            img_bgr: BGRæ ¼å¼çš„å›¾ç‰‡æ•°ç»„
            top_k: è¿”å›å‰kä¸ªæœ€ç›¸ä¼¼çš„ç±»åˆ«
            use_all_embeddings: æ˜¯å¦ä½¿ç”¨æ‰€æœ‰ç‰¹å¾è¿›è¡ŒåŒ¹é…
        
        Returns:
            list: [(ç±»åˆ«å, ç›¸ä¼¼åº¦), ...]
        """
        if len(self.class_embeddings) == 0:
            raise ValueError("è¯·å…ˆè°ƒç”¨ train_from_directory è¿›è¡Œè®­ç»ƒï¼")
        
        test_emb = self.extract_embedding_from_array(img_bgr)
        
        if test_emb is None:
            return []
        
        results = []
        
        if use_all_embeddings and self.class_all_embeddings:
            for class_name, embeddings in self.class_all_embeddings.items():
                max_sim = max(self.compute_similarity(test_emb, emb) for emb in embeddings)
                results.append((class_name, max_sim))
        else:
            for class_name, class_emb in self.class_embeddings.items():
                sim = self.compute_similarity(test_emb, class_emb)
                results.append((class_name, sim))
        
        results.sort(key=lambda x: x[1], reverse=True)
        return results[:top_k]
    
    def classify_batch(self, test_image_paths: List[str], top_k: int = 1,
                       use_all_embeddings: bool = False) -> List[dict]:
        """
        æ‰¹é‡åˆ†ç±»å¤šå¼ æµ‹è¯•å›¾ç‰‡
        
        Args:
            test_image_paths: æµ‹è¯•å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            top_k: æ¯å¼ å›¾ç‰‡è¿”å›å‰kä¸ªæœ€ç›¸ä¼¼çš„ç±»åˆ«
            use_all_embeddings: æ˜¯å¦ä½¿ç”¨æ‰€æœ‰ç‰¹å¾è¿›è¡ŒåŒ¹é…
        
        Returns:
            list: [{'image_path': è·¯å¾„, 'predictions': [(ç±»åˆ«å, ç›¸ä¼¼åº¦), ...]}, ...]
        """
        results = []
        
        for img_path in tqdm(test_image_paths, desc="åˆ†ç±»è¿›åº¦"):
            try:
                predictions = self.classify_image(
                    img_path, top_k=top_k, use_all_embeddings=use_all_embeddings
                )
                results.append({
                    'image_path': img_path,
                    'predictions': predictions
                })
            except Exception as e:
                print(f"\nå¤„ç†å¤±è´¥ {img_path}: {str(e)}")
                results.append({
                    'image_path': img_path,
                    'predictions': []
                })
        
        return results
    
    def save_embeddings(self, save_path: str) -> None:
        """
        ä¿å­˜è®­ç»ƒå¥½çš„ç‰¹å¾åˆ°æ–‡ä»¶
        
        Args:
            save_path: ä¿å­˜è·¯å¾„ (.npz)
        """
        if len(self.class_embeddings) == 0:
            raise ValueError("æ²¡æœ‰è®­ç»ƒæ•°æ®å¯ä¿å­˜")
        
        # å‡†å¤‡ä¿å­˜æ•°æ®
        data = {
            'class_names': list(self.class_embeddings.keys()),
            'embeddings': np.array([self.class_embeddings[name] for name in self.class_embeddings.keys()]),
            'image_counts': np.array([self.class_image_counts[name] for name in self.class_embeddings.keys()])
        }
        
        np.savez(save_path, **data)
        print(f"âœ… ç‰¹å¾å·²ä¿å­˜åˆ°: {save_path}")
    
    def load_embeddings(self, load_path: str) -> None:
        """
        ä»æ–‡ä»¶åŠ è½½è®­ç»ƒå¥½çš„ç‰¹å¾
        
        Args:
            load_path: æ–‡ä»¶è·¯å¾„ (.npz)
        """
        if not os.path.exists(load_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {load_path}")
        
        data = np.load(load_path, allow_pickle=True)
        class_names = data['class_names']
        embeddings = data['embeddings']
        image_counts = data['image_counts']
        
        self.class_embeddings = {name: emb for name, emb in zip(class_names, embeddings)}
        self.class_image_counts = {name: int(count) for name, count in zip(class_names, image_counts)}
        
        print(f"âœ… å·²åŠ è½½ {len(self.class_embeddings)} ä¸ªç±»åˆ«çš„ç‰¹å¾")


def demo_multi_class_classification():
    """å¤šç±»åˆ«è®­ç»ƒ + åˆ†ç±»åŒ¹é… ç¤ºä¾‹"""
    print("=" * 70)
    print("InsightFace å¤šç±»åˆ«äººè„¸è¯†åˆ«")
    print("=" * 70)
    
    # åˆ›å»ºè¯†åˆ«å™¨
    recognizer = InsightFaceRecognizer(
        model_name='buffalo_l',  # å¯é€‰: buffalo_l, buffalo_s, buffalo_sc
        ctx_id=0  # GPU IDï¼Œ-1 è¡¨ç¤º CPU
    )
    
    # ========== é…ç½®å‚æ•° ==========
    # è®­ç»ƒç›®å½•ï¼ˆå­ç›®å½•æ˜¯æ ‡ç­¾ï¼Œå­ç›®å½•ä¸‹çš„å›¾ç‰‡æ˜¯æ•°æ®ï¼‰
    train_directory = "classmate_photo_processed/"
    
    # æµ‹è¯•å›¾ç‰‡è·¯å¾„
    test_image_path = "frame_261436_id_0028_n_0006.jpg"
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªæœ€ç›¸ä¼¼çš„äºº
    top_k = 5
    
    print(f"\nè®­ç»ƒç›®å½•: {train_directory}")
    print(f"æµ‹è¯•å›¾ç‰‡: {test_image_path}")
    print("-" * 70)
    
    try:
        # ========== æ­¥éª¤1: å¤šç±»åˆ«è®­ç»ƒ ==========
        print("\nã€æ­¥éª¤1ã€‘å¤šç±»åˆ«è®­ç»ƒ...")
        class_counts = recognizer.train_from_directory(
            train_dir=train_directory,
            aggregation='mean',
            max_images_per_class=50
        )
        
        # å¯é€‰ï¼šä¿å­˜ç‰¹å¾ä»¥ä¾¿ä¸‹æ¬¡å¿«é€ŸåŠ è½½
        # recognizer.save_embeddings("face_embeddings.npz")
        
        # ========== æ­¥éª¤2: åˆ†ç±»æµ‹è¯•å›¾ç‰‡ ==========
        print(f"\nã€æ­¥éª¤2ã€‘æ­£åœ¨è¯†åˆ«æµ‹è¯•å›¾ç‰‡: {test_image_path}")
        predictions = recognizer.classify_image(
            test_image_path=test_image_path,
            top_k=top_k,
            use_all_embeddings=False  # True æ›´å‡†ç¡®ä½†æ›´æ…¢
        )
        
        if len(predictions) == 0:
            print("\nâŒ æœªèƒ½åœ¨æµ‹è¯•å›¾ç‰‡ä¸­æ£€æµ‹åˆ°äººè„¸ï¼")
            return
        
        # æ˜¾ç¤ºç»“æœ
        print("\n" + "=" * 70)
        print("ğŸ¯ è¯†åˆ«ç»“æœï¼ˆæŒ‰ç›¸ä¼¼åº¦é™åºï¼‰")
        print("=" * 70)
        
        for i, (class_name, similarity) in enumerate(predictions, 1):
            bar_len = int(similarity * 30)
            bar = "â–ˆ" * bar_len + "â–‘" * (30 - bar_len)
            print(f"{i}. {class_name}")
            print(f"   ç›¸ä¼¼åº¦: {similarity:.4f} [{bar}]")
            print()
        
        # æœ€ç»ˆé¢„æµ‹
        best_class, best_score = predictions[0]
        print("=" * 70)
        print(f"ğŸ† æœ€ç»ˆé¢„æµ‹: {best_class}")
        print(f"   ç½®ä¿¡åº¦: {best_score:.4f}")
        print("=" * 70)
        
    except FileNotFoundError as e:
        print(f"\nâŒ é”™è¯¯: {e}")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 70)
    print("ä½¿ç”¨è¯´æ˜:")
    print("=" * 70)
    print("""
    1. å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆç›®å½•ç»“æ„ï¼‰ï¼š
       train_dir/
       â”œâ”€â”€ å¼ ä¸‰/        <- å­ç›®å½•å = äººå
       â”‚   â”œâ”€â”€ img1.jpg
       â”‚   â””â”€â”€ img2.jpg
       â”œâ”€â”€ æå››/
       â”‚   â””â”€â”€ ...
       â””â”€â”€ ç‹äº”/
           â””â”€â”€ ...
    
    2. API ä½¿ç”¨æ–¹æ³•ï¼š
       recognizer = InsightFaceRecognizer()
       recognizer.train_from_directory("train_dir/")
       result = recognizer.classify_image("test.jpg", top_k=5)
    
    3. ä¿å­˜/åŠ è½½ç‰¹å¾ï¼ˆåŠ é€Ÿåç»­ä½¿ç”¨ï¼‰ï¼š
       recognizer.save_embeddings("embeddings.npz")
       recognizer.load_embeddings("embeddings.npz")
    
    4. æ¨¡å‹é€‰æ‹©ï¼š
       - buffalo_l: ç²¾åº¦æœ€é«˜ï¼ˆæ¨èï¼‰
       - buffalo_s: é€Ÿåº¦å’Œç²¾åº¦å¹³è¡¡
       - buffalo_sc: æœ€å¿«ï¼Œé€‚åˆè¾¹ç¼˜è®¾å¤‡
    """)


if __name__ == "__main__":
    demo_multi_class_classification()
